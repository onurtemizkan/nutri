# ML Engine End-to-End Testing Suite

Comprehensive testing suite for the **Nutri ML Engine** - validates all three phases from raw data to interpretability.

## ðŸŽ¯ Overview

This test suite ensures the ML Engine works end-to-end with **realistic data patterns** and **actual correlations**:

```
ðŸ“Š Phase 1: Feature Engineering & Correlation Analysis
    â†“
ðŸ§  Phase 2: PyTorch LSTM Training & Predictions
    â†“
ðŸ” Phase 3: Model Interpretability & Explainability
```

### Key Features

âœ… **Realistic Test Data** - 90 days of meals, activities, and health metrics with REAL correlations
âœ… **Complete Coverage** - Tests all 51 features, LSTM training, predictions, and interpretability
âœ… **Performance Validation** - Ensures models achieve RÂ² > 0.5 and MAPE < 15%
âœ… **Pattern Discovery** - Validates ML discovers built-in correlations (protein â†’ RHR, etc.)
âœ… **Async Support** - All tests use async/await with pytest-asyncio

---

## ðŸ“ Test Files

### Core Test Files

| File | Tests | Runtime | Description |
|------|-------|---------|-------------|
| `test_e2e_phase1.py` | 8 tests | ~30s | Feature engineering (51 features) + correlation analysis |
| `test_e2e_phase2.py` | 10 tests | ~5 min | PyTorch LSTM training + predictions |
| `test_e2e_phase3.py` | 8 tests | ~2 min | SHAP, attention, what-if, counterfactuals |
| `test_e2e_full_pipeline.py` | 2 tests | ~5 min | **THE ULTIMATE TEST** - All phases together |

### Supporting Files

| File | Purpose |
|------|---------|
| `fixtures.py` | `TestDataGenerator` - Creates 90 days of realistic data |
| `conftest.py` | Pytest configuration, shared fixtures, assertion helpers |
| `__init__.py` | Test package initialization |
| `README.md` | This documentation |

---

## ðŸš€ Running Tests

### Quick Start

```bash
# Run all tests (fast tests only - skips slow model training)
pytest tests/ -v

# Run all tests including slow tests (model training)
pytest tests/ -v -m slow

# Run specific phase
pytest tests/test_e2e_phase1.py -v
pytest tests/test_e2e_phase2.py -v
pytest tests/test_e2e_phase3.py -v

# Run the ULTIMATE test (full pipeline)
pytest tests/test_e2e_full_pipeline.py -v -s
```

### Test Markers

```bash
# Run only fast tests (skip model training)
pytest tests/ -v -m "not slow"

# Run only slow tests (model training)
pytest tests/ -v -m slow

# Run only integration tests
pytest tests/ -v -m integration

# Run only unit tests
pytest tests/ -v -m unit
```

### Verbose Output

```bash
# Show detailed output (recommended for debugging)
pytest tests/ -v -s

# Show only test names
pytest tests/ -v

# Minimal output
pytest tests/
```

---

## ðŸ“Š Test Data Generation

### The TestDataGenerator

Located in `fixtures.py`, this class generates **realistic** test data with **actual correlations**:

```python
from tests.fixtures import TestDataGenerator

generator = TestDataGenerator(seed=42)
dataset = generator.generate_complete_dataset()

# Returns:
# {
#   "user": {...},           # User profile (John - athlete)
#   "meals": [...],          # ~350 meals (3-5 per day)
#   "activities": [...],     # ~75 activities (5-6 workouts/week)
#   "health_metrics": [...]  # 180 metrics (RHR + HRV daily)
# }
```

### Built-in Correlations

The test data has **REAL correlations** so the ML model can learn:

| Feature | Effect on RHR | Effect on HRV |
|---------|---------------|---------------|
| **High protein** (>180g) | -2 BPM â†“ | +5 ms â†‘ |
| **Late night carbs** (>50g after 8pm) | +1-3 BPM â†‘ | No effect |
| **High intensity workout** (>0.8) | +3 BPM next day â†‘ | -8 ms next day â†“ |
| **Rest day** (no workout) | -1 BPM â†“ | +3 ms â†‘ |

This ensures the ML engine can **actually learn meaningful patterns** from the data!

### Data Patterns

**Meal patterns** (90 days):
- **Normal days**: ~2500 cal, 150g protein, 300g carbs
- **High protein days** (every 3rd day): 200g protein
- **Rest days** (Sundays): Lower calories
- **Cheat days** (Saturdays): Higher carbs

**Activity patterns**:
- **Workout days**: 5-6 days/week, 45-90 minutes
- **Intensity**: 0.4-0.9 (varied training)
- **Rest days**: Light walks only

**Health metrics**:
- **RHR baseline**: 55 BPM (athlete)
- **HRV baseline**: 65 ms (SDNN)
- **Realistic noise**: Â±1-2 BPM/ms
- **Momentum**: Gradual changes (not instant)

---

## ðŸ§ª Test Scenarios

### Phase 1: Feature Engineering Tests

**Test**: `test_feature_engineering_complete`
- âœ“ Generates all 51 features from 90 days of data
- âœ“ Covers all 5 categories (nutrition, activity, health, temporal, interaction)
- âœ“ Feature values are realistic
- âœ“ Data quality score â‰¥ 0.85

**Test**: `test_correlation_analysis_discovers_relationships`
- âœ“ Discovers protein â†’ RHR correlation (negative)
- âœ“ Discovers intensity â†’ RHR correlation (positive)
- âœ“ Discovers late carbs â†’ RHR correlation (positive)
- âœ“ Identifies strongest positive and negative correlations

**Test**: `test_lag_analysis_finds_delayed_effects`
- âœ“ Tests correlations at different time lags (0-48 hours)
- âœ“ Finds optimal lag (when effect is strongest)
- âœ“ Identifies immediate vs delayed effects
- âœ“ Generates natural language interpretation

### Phase 2: Model Training Tests

**Test**: `test_lstm_model_training_rhr`
- âœ“ Trains PyTorch LSTM with 90 days of data
- âœ“ Achieves RÂ² > 0.5 (explains >50% variance)
- âœ“ Achieves MAPE < 15% (predictions within 15%)
- âœ“ Saves model artifacts (weights, metadata, scalers)
- âœ“ Model is production-ready

**Test**: `test_single_prediction`
- âœ“ Loads trained model
- âœ“ Makes prediction for tomorrow
- âœ“ Prediction is realistic (40-80 BPM for RHR)
- âœ“ Confidence interval is calculated
- âœ“ Historical context is provided
- âœ“ Natural language interpretation
- âœ“ Actionable recommendations

**Test**: `test_batch_predictions`
- âœ“ Predicts multiple metrics at once (RHR + HRV)
- âœ“ All successful predictions are returned
- âœ“ Failed metrics are reported
- âœ“ Overall data quality is calculated

### Phase 3: Interpretability Tests

**Test**: `test_shap_local_explanation`
- âœ“ SHAP values calculated for all features
- âœ“ Features ranked by importance
- âœ“ Impact direction identified (positive/negative)
- âœ“ Impact magnitude categorized (strong/moderate/weak)
- âœ“ Top features match known correlations
- âœ“ Natural language summary

**Test**: `test_what_if_multiple_scenarios`
- âœ“ Tests 3 hypothetical scenarios
- âœ“ "High Protein Day" (+60g protein)
- âœ“ "High Intensity Workout" (intensity 0.9)
- âœ“ "Perfect Day" (protein+, carbs-, moderate workout)
- âœ“ Identifies best and worst scenarios
- âœ“ Generates recommendations

**Test**: `test_counterfactual_target_value`
- âœ“ Finds minimal changes to reach target
- âœ“ Target: 5 BPM lower than current
- âœ“ Suggests â‰¤3 changes
- âœ“ Changes are realistic
- âœ“ Plausibility score calculated
- âœ“ Natural language summary

### Full Pipeline Test

**Test**: `test_complete_ml_pipeline_end_to_end`

This is the **ULTIMATE TEST** - validates the entire ML Engine:

```
1. Create user with 90 days of realistic data
2. Engineer 51 features âœ“
3. Discover correlations âœ“
4. Analyze time-delayed effects âœ“
5. Train PyTorch LSTM model âœ“
6. Make predictions âœ“
7. Generate SHAP explanations âœ“
8. Calculate global importance âœ“
9. Test what-if scenarios âœ“
10. Generate counterfactuals âœ“
```

**Expected output**:
```
ðŸš€ STARTING FULL PIPELINE E2E TEST
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ðŸ“Š PHASE 1: Feature Engineering & Correlation Analysis
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Generated 51 features
âœ… Data quality: 0.94
âœ… Found 8 significant correlations

ðŸ§  PHASE 2: Model Training & Predictions
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Model trained successfully!
   RÂ² Score: 0.67 (>0.5 = good âœ“)
   MAPE: 8.5% (<15% = good âœ“)
âœ… Prediction for 2025-01-18:
   Predicted RHR: 58.3 BPM
   Confidence: 0.87

ðŸ” PHASE 3: Interpretability & Explainability
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… SHAP explanation generated
âœ… Global importance calculated
âœ… What-if scenarios tested
âœ… Counterfactual explanation generated

âœ… FULL PIPELINE TEST COMPLETED SUCCESSFULLY!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## âœ… Quality Gates

All tests validate these quality gates:

### Feature Engineering
- âœ… All 51 features generated
- âœ… Data quality score â‰¥ 0.85
- âœ… Missing features â‰¤ 3
- âœ… Feature values are realistic

### Correlation Analysis
- âœ… Discovers â‰¥3 significant correlations
- âœ… P-values < 0.05 (statistically significant)
- âœ… Top correlations match known patterns

### Model Training
- âœ… **RÂ² > 0.5** (explains >50% variance)
- âœ… **MAPE < 15%** (predictions within 15%)
- âœ… MAE > 0, RMSE > 0
- âœ… Early stopping works (prevents overfitting)
- âœ… Model artifacts saved

### Predictions
- âœ… Predictions are realistic (40-80 BPM for RHR)
- âœ… Confidence interval is valid (lower < predicted < upper)
- âœ… Confidence score is 0-1
- âœ… Historical context provided
- âœ… Natural language interpretation

### Interpretability
- âœ… SHAP values calculated for all features
- âœ… Features ranked by importance
- âœ… Impact direction identified
- âœ… What-if scenarios work
- âœ… Counterfactuals find minimal changes

---

## ðŸ› ï¸ Test Utilities

### Assertion Helpers (conftest.py)

```python
from tests.conftest import (
    assert_valid_rhr,
    assert_valid_hrv,
    assert_good_model_performance,
    assert_valid_confidence_interval,
    assert_valid_shap_values,
)

# Usage
assert_valid_rhr(58.5)  # Validates RHR is 40-100 BPM
assert_good_model_performance(r2=0.67, mape=8.5)  # RÂ² > 0.5, MAPE < 15%
```

### Shared Fixtures

```python
# Database fixtures (automatically injected)
async def test_something(db: AsyncSession):
    # db is a fresh test database session
    pass

# Sample data fixtures
def test_something(sample_user_data, sample_meal_data):
    # Pre-made sample data dictionaries
    pass

# Benchmark timer
def test_performance(benchmark_timer):
    with benchmark_timer("Feature Engineering"):
        # Code to benchmark
        pass
```

---

## ðŸ› Debugging Tests

### View SQL Queries

Edit `conftest.py` and set `echo=True`:

```python
engine = create_async_engine(
    "sqlite+aiosqlite:///:memory:",
    echo=True,  # Shows all SQL queries
)
```

### View Detailed Output

```bash
# Show all print statements
pytest tests/ -v -s

# Show only failing tests
pytest tests/ -v -x  # Stop on first failure

# Run specific test
pytest tests/test_e2e_phase1.py::test_feature_engineering_complete -v -s
```

### Common Issues

**Issue**: `ImportError: No module named 'app'`
```bash
# Solution: Run from ml-service directory
cd ml-service
pytest tests/ -v
```

**Issue**: Tests hang or timeout
```bash
# Solution: Increase timeout in test
async with AsyncClient(app=app, timeout=600.0) as client:
    ...
```

**Issue**: Model training fails with "insufficient data"
```bash
# Solution: Ensure test data generator creates enough data
# Check: len(meals) should be ~350, len(metrics) should be 180
```

---

## ðŸ“ˆ Performance Benchmarks

Expected runtimes on modern hardware (M1 Mac, 16GB RAM):

| Test Suite | Tests | Runtime | Notes |
|------------|-------|---------|-------|
| Phase 1 (fast) | 8 | 30s | Feature engineering + correlation |
| Phase 2 (slow) | 10 | 5 min | Includes LSTM training (50 epochs) |
| Phase 3 (medium) | 8 | 2 min | Requires trained model |
| Full Pipeline (slow) | 2 | 5 min | THE ULTIMATE TEST |
| **All tests** | **28** | **12 min** | With all slow tests |

---

## ðŸŽ¯ Test Coverage

### Feature Coverage

- âœ… **51/51 features** (100%)
  - Nutrition: 15 features
  - Activity: 12 features
  - Health: 10 features
  - Temporal: 8 features
  - Interaction: 6 features

### Endpoint Coverage

- âœ… **Phase 1**: 5/5 endpoints (100%)
  - POST `/api/features/engineer`
  - GET `/api/features/{user_id}/{date}`
  - GET `/api/features/{user_id}/{date}/summary`
  - POST `/api/correlations/analyze`
  - POST `/api/correlations/lag-analysis`

- âœ… **Phase 2**: 6/6 endpoints (100%)
  - POST `/api/predictions/train`
  - POST `/api/predictions/predict`
  - POST `/api/predictions/batch-predict`
  - GET `/api/predictions/models/{user_id}`
  - DELETE `/api/predictions/models/{model_id}`

- âœ… **Phase 3**: 4/4 endpoints (100%)
  - POST `/api/interpretability/explain`
  - POST `/api/interpretability/global-importance`
  - POST `/api/interpretability/what-if`
  - POST `/api/interpretability/counterfactual`

### Code Coverage

Run with pytest-cov:

```bash
pytest tests/ --cov=app --cov-report=html
open htmlcov/index.html
```

---

## ðŸš€ CI/CD Integration

### GitHub Actions

```yaml
name: E2E Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: 3.11

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Run fast tests
        run: pytest tests/ -v -m "not slow"

      - name: Run slow tests (model training)
        run: pytest tests/ -v -m slow
        if: github.event_name == 'push'
```

---

## ðŸ“ Adding New Tests

### Step 1: Create Test File

```python
# tests/test_new_feature.py
import pytest
from httpx import AsyncClient
from tests.fixtures import TestDataGenerator

@pytest.mark.asyncio
async def test_new_feature(db):
    """Test description."""
    # Create test data
    generator = TestDataGenerator()
    dataset = generator.generate_complete_dataset()

    # Add to database
    # ...

    # Make API call
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.post("/api/new-endpoint", json={...})

    # Assertions
    assert response.status_code == 200
    # ...
```

### Step 2: Add to Test Suite

```bash
# Run your new test
pytest tests/test_new_feature.py -v -s
```

### Step 3: Update Documentation

Add your test to this README in the appropriate section.

---

## ðŸŽ‰ Summary

This test suite ensures the **Nutri ML Engine** works flawlessly from raw data to actionable insights:

âœ… **Realistic Data** - 90 days with actual correlations
âœ… **Complete Coverage** - All 51 features, LSTM training, interpretability
âœ… **Quality Gates** - RÂ² > 0.5, MAPE < 15%, validates patterns
âœ… **Fast Feedback** - Fast tests run in 30s, full suite in 12 min
âœ… **Easy to Run** - `pytest tests/ -v`

**Run the ULTIMATE test**:
```bash
pytest tests/test_e2e_full_pipeline.py::test_complete_ml_pipeline_end_to_end -v -s
```

This validates EVERYTHING works together! ðŸš€
