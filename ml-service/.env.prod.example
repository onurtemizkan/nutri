# =============================================================================
# Nutri ML Service - Production Environment Variables
# Optimized for Hetzner Cloud/Dedicated Servers (AMD EPYC)
# =============================================================================
#
# Copy this file to .env.prod and fill in your values:
#   cp .env.prod.example .env.prod
#
# Then deploy with:
#   docker compose -f docker-compose.prod.yml --env-file .env.prod up -d --build
#
# =============================================================================

# -----------------------------------------------------------------------------
# Database Configuration
# -----------------------------------------------------------------------------
# PostgreSQL connection for ML service (uses asyncpg driver)
DATABASE_URL=postgresql+asyncpg://postgres:YOUR_SECURE_PASSWORD@postgres:5432/nutri_db

# PostgreSQL credentials (used by postgres container)
POSTGRES_USER=postgres
POSTGRES_PASSWORD=YOUR_SECURE_PASSWORD
POSTGRES_DB=nutri_db

# -----------------------------------------------------------------------------
# Redis Configuration
# -----------------------------------------------------------------------------
REDIS_URL=redis://redis:6379/0

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# ML Performance Settings
# -----------------------------------------------------------------------------
# FAST_MODE=true: Disable OWL-ViT for ~18x faster inference (~150ms vs ~3s)
# Set to false only if you need multi-food detection AND have a GPU
FAST_MODE=true

# Force CPU device (no GPU search)
COMPUTE_DEVICE=cpu

# Don't skip warmup in production (models load on startup)
SKIP_MODEL_WARMUP=false

# -----------------------------------------------------------------------------
# AMD EPYC Thread Optimization
# Adjust based on your Hetzner instance:
#   - CPX21 (3 vCPU):  OMP_NUM_THREADS=3
#   - CPX31 (4 vCPU):  OMP_NUM_THREADS=4
#   - CCX13 (2 dedicated): OMP_NUM_THREADS=2
#   - CCX23 (4 dedicated): OMP_NUM_THREADS=4
# -----------------------------------------------------------------------------
OMP_NUM_THREADS=4
MKL_NUM_THREADS=4
OPENBLAS_NUM_THREADS=4
TORCH_NUM_THREADS=4
NUMEXPR_NUM_THREADS=4

# -----------------------------------------------------------------------------
# Backend API Settings (passed to backend container)
# -----------------------------------------------------------------------------
JWT_SECRET=CHANGE_THIS_TO_A_SECURE_RANDOM_STRING_AT_LEAST_32_CHARS
JWT_EXPIRES_IN=7d

# -----------------------------------------------------------------------------
# Optional: External Services
# -----------------------------------------------------------------------------
# Sentry DSN for error tracking (optional)
# SENTRY_DSN=https://xxx@sentry.io/xxx

# =============================================================================
# Hetzner Instance Recommendations
# =============================================================================
#
# MVP (< 1000 DAU):
#   Instance: CPX31 (4 vCPU, 8GB RAM) - €9/mo
#   Expected latency: 150-200ms
#   OMP_NUM_THREADS=4
#
# Growth (1000-5000 DAU):
#   Instance: CCX23 (4 dedicated, 16GB RAM) - €25/mo
#   Expected latency: 100-150ms
#   OMP_NUM_THREADS=4
#
# Scale (5000+ DAU):
#   Consider: Multiple CCX23 behind load balancer
#   Or upgrade to: GEX44 GPU (€184/mo) for <50ms latency
#
# =============================================================================
