# Nutri ML Service ğŸ§ 

**In-House Machine Learning API for personalized nutrition insights**

Version: 1.0.0
Framework: FastAPI + SQLAlchemy + Redis
Python: 3.11+

---

## ğŸš¨ IMPORTANT - In-House ML Only

**All ML models are built, trained, and deployed IN-HOUSE**

- âœ… **We build** all ML models using open-source libraries (PyTorch, scikit-learn)
- âœ… **We train** all models on our infrastructure with user data
- âœ… **We own** all models and intellectual property
- âŒ **NOT using** external ML APIs (OpenAI, Claude, AWS ML, Google AI, Azure ML, etc.)
- âŒ **NOT a chatbot** - This service provides structured data/predictions, not conversational AI

**ML Stack (All In-House)**:
- **PyTorch** (LSTM neural networks for time series prediction)
- scikit-learn (correlation analysis, regression, Isolation Forest)
- XGBoost (gradient boosting for HRV prediction)
- statsmodels (Granger causality, statistical tests)
- scipy (Pearson/Spearman correlation)
- Prophet (Facebook's time series library)

---

## ğŸ¯ What This Service Does

The Nutri ML Service analyzes the relationship between:
- **Inputs** (what we control): Nutrition (meals, timing, macros), Activity (workouts, intensity)
- **Outputs** (what we optimize): Health metrics from smartwatches (RHR, HRV, sleep, recovery)

**Goal**: Understand how nutrition and eating schedules affect health metrics to provide personalized recommendations.

**Core Capabilities**:
1. **Feature Engineering**: Transforms raw data into 50+ ML features
2. **Correlation Analysis**: Finds patterns (e.g., "high protein â†’ better HRV")
3. **Predictions**: Forecasts tomorrow's RHR, HRV using our LSTM models
4. **Insights**: Generates actionable recommendations based on user's data

---

## ğŸ“ Project Structure

```
ml-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py               # Configuration (env variables)
â”‚   â”œâ”€â”€ database.py             # Async PostgreSQL connection
â”‚   â”œâ”€â”€ redis_client.py         # Redis caching layer
â”‚   â”œâ”€â”€ models/                 # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ meal.py
â”‚   â”‚   â”œâ”€â”€ health_metric.py
â”‚   â”‚   â””â”€â”€ activity.py
â”‚   â”œâ”€â”€ schemas/                # Pydantic schemas (TODO)
â”‚   â”œâ”€â”€ services/               # Business logic (TODO)
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”‚   â”œâ”€â”€ correlation_engine.py
â”‚   â”‚   â””â”€â”€ prediction_service.py
â”‚   â””â”€â”€ api/                    # API routes (TODO)
â”‚       â”œâ”€â”€ ml.py
â”‚       â””â”€â”€ correlations.py
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                  # Docker image
â”œâ”€â”€ docker-compose.yml          # Local development stack
â”œâ”€â”€ .env.example                # Environment variables template
â””â”€â”€ README.md                   # This file
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- PostgreSQL 16+ (or use Docker)
- Redis 7+ (or use Docker)

### Option 1: Local Development (Python Virtual Environment)

```bash
# 1. Create virtual environment
cd ml-service
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Copy environment variables
cp .env.example .env
# Edit .env with your database credentials

# 4. Run the service
python -m app.main
# Or with uvicorn:
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Option 2: Docker (Recommended)

```bash
# Start entire stack (PostgreSQL + Redis + ML Service)
docker-compose up -d

# View logs
docker-compose logs -f ml-service

# Stop stack
docker-compose down
```

---

## ğŸ¥ Health Checks

Once running, verify the service:

```bash
# Root endpoint
curl http://localhost:8000/

# Health check
curl http://localhost:8000/health

# Readiness check
curl http://localhost:8000/ready

# API documentation (Swagger UI)
open http://localhost:8000/docs
```

**Expected response**:
```json
{
  "status": "healthy",
  "service": "Nutri ML Service",
  "version": "1.0.0",
  "environment": "development",
  "dependencies": {
    "database": "healthy",
    "redis": "healthy"
  }
}
```

---

## ğŸ”§ Configuration

All configuration is done via environment variables (see `.env.example`):

| Variable | Default | Description |
|----------|---------|-------------|
| `DATABASE_URL` | `postgresql+asyncpg://...` | PostgreSQL connection string |
| `REDIS_URL` | `redis://localhost:6379/0` | Redis connection string |
| `ENVIRONMENT` | `development` | Environment (development/staging/production) |
| `DEBUG` | `true` | Enable debug mode and SQL logging |
| `LOG_LEVEL` | `INFO` | Logging level (DEBUG/INFO/WARNING/ERROR) |
| `CACHE_TTL_FEATURES` | `3600` | Feature cache TTL (1 hour) |
| `CACHE_TTL_PREDICTIONS` | `86400` | Prediction cache TTL (24 hours) |
| `MIN_DATA_POINTS_FOR_ML` | `30` | Minimum days of data required for ML |

---

## ğŸ§ª API Endpoints (Planned)

### Health & Status
- `GET /` - Service information
- `GET /health` - Health check with dependencies
- `GET /ready` - Readiness check for load balancers

### Features (TODO)
- `POST /api/features/engineer` - Engineer features for user
- `GET /api/features/{userId}/{date}` - Get cached features

### Correlations (TODO)
- `GET /api/correlations/{userId}` - Get correlations for all metrics
- `GET /api/correlations/{userId}/{metricType}` - Correlations for specific metric

### Predictions (TODO)
- `POST /api/predictions/rhr` - Predict tomorrow's RHR
- `POST /api/predictions/hrv` - Predict tomorrow's HRV
- `GET /api/predictions/{userId}/{date}` - Get cached predictions

### Insights (TODO)
- `GET /api/insights/{userId}` - Get personalized insights
- `POST /api/insights/{userId}/generate` - Generate new insights

---

## ğŸ—„ï¸ Database Models

The ML service reads from the same PostgreSQL database as the Node.js backend:

**Tables used**:
- `User` - User profile and goals
- `Meal` - Nutrition tracking
- `HealthMetric` - RHR, HRV, sleep, steps, etc.
- `Activity` - Workouts and exercise

**Tables created** (Phase 1):
- `MLFeature` - Pre-computed features (for fast predictions)
- `MLPrediction` - Model outputs and tracking
- `MLInsight` - User-facing insights

---

## ğŸ§  ML Pipeline (Overview)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data   â”‚  â† Meals, Activities, Health Metrics from DB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Engineering Service            â”‚
â”‚  - Nutrition features (protein_7d_avg)  â”‚
â”‚  - Activity features (recovery_time)    â”‚
â”‚  - Health features (rhr_trend)          â”‚
â”‚  - Temporal features (day_of_week)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Cache (1h TTL)                   â”‚
â”‚  Key: features:{userId}:{date}:daily    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ML Models                               â”‚
â”‚  - LSTM for RHR prediction              â”‚
â”‚  - XGBoost for HRV prediction           â”‚
â”‚  - Correlation engine                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Cache (24h TTL)                  â”‚
â”‚  Key: prediction:{userId}:{metric}:date â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Responseâ”‚  â†’ Returned to client
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Cache Strategy

**Redis is used for**:
1. **Engineered features** (TTL: 1 hour)
   - Key pattern: `features:{userId}:{date}:{category}`
   - Reduces DB queries and computation time

2. **Predictions** (TTL: 24 hours)
   - Key pattern: `prediction:{userId}:{metricType}:{date}`
   - Predictions are expensive, cache aggressively

3. **Model artifacts** (TTL: 7 days)
   - Key pattern: `model:{modelId}:{version}`
   - Avoid reloading models from disk

**Cache invalidation**:
- When new data is added for a user â†’ invalidate their features
- When model is retrained â†’ invalidate all predictions for that metric

---

## ğŸ”¬ Development

### Running tests (TODO)
```bash
pytest tests/ -v
pytest tests/ --cov=app --cov-report=html
```

### Code quality
```bash
# Format code
black app/

# Lint
flake8 app/

# Type checking
mypy app/
```

### Database migrations (TODO - Alembic)
```bash
# Generate migration
alembic revision --autogenerate -m "Add new ML tables"

# Run migrations
alembic upgrade head

# Rollback
alembic downgrade -1
```

---

## ğŸš§ TODO (Phase 1 - Feature Engineering)

- [ ] Create `services/feature_engineering.py`
- [ ] Create `services/correlation_engine.py`
- [ ] Create `api/features.py` (API routes)
- [ ] Create `api/correlations.py` (API routes)
- [ ] Write unit tests for feature engineering
- [ ] Add Prometheus metrics for monitoring

---

## ğŸš§ TODO (Phase 2 - Predictions)

- [ ] Train LSTM model for RHR prediction
- [ ] Train XGBoost model for HRV prediction
- [ ] Create `services/prediction_service.py`
- [ ] Create `api/predictions.py` (API routes)
- [ ] Model evaluation pipeline
- [ ] A/B testing framework

---

## ğŸš§ TODO (Phase 3 - Insights)

- [ ] Create `services/insight_generator.py`
- [ ] Natural language templates for insights
- [ ] Create `api/insights.py` (API routes)
- [ ] User feedback loop (was this insight helpful?)

---

## ğŸ“ Notes

- **Async all the way**: All database and Redis operations are async for better performance
- **Type-safe**: Uses Pydantic for request/response validation
- **Cached aggressively**: Features and predictions are expensive, cache them
- **Stateless**: ML service is stateless and can scale horizontally
- **Separation of concerns**: Node.js handles CRUD, Python handles ML

---

## ğŸ¤ Integration with Node.js Backend

**Node.js backend** (`http://localhost:3000`):
- Handles user authentication (JWT)
- CRUD operations for meals, activities, health metrics
- Serves React Native app

**Python ML service** (`http://localhost:8000`):
- Reads data from same PostgreSQL database
- Performs ML computations
- Returns predictions and insights
- Node.js backend calls ML service when needed

**Communication flow**:
```
React Native App
       â†“ (JWT auth)
Node.js Backend (port 3000)
       â†“ (internal HTTP call)
Python ML Service (port 8000)
       â†“ (reads)
PostgreSQL Database
```

---

## ğŸ“„ License

Part of the Nutri nutrition tracking application.

---

**Status**: Phase 0 Complete âœ…
**Next**: Phase 1 (Feature Engineering & Correlation Analysis)
