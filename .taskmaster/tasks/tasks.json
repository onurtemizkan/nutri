{
  "master": {
    "tasks": [
      {
        "id": 2,
        "title": "Implement Real Food Classification ML Model",
        "description": "Replace the mock food classifier in ml-service/app/services/food_analysis_service.py with a real CNN model (EfficientNet or ResNet) trained on food image datasets.",
        "details": "1. Create a new module `ml-service/app/ml_models/food_classifier.py` with:\n   - Load pre-trained EfficientNet-B0 or ResNet-50 from torchvision\n   - Fine-tune on Food-101 dataset or custom food dataset\n   - Implement proper image preprocessing pipeline matching ImageNet stats\n   - Support for GPU inference if available (auto-detect CUDA)\n\n2. Update `food_analysis_service.py`:\n   - Replace `NUTRITION_DATABASE` with a proper food database (USDA FoodData Central API integration)\n   - Update `_classify_food()` to use real model inference instead of random selection\n   - Add model loading with caching to avoid reloading on each request\n   - Implement top-5 predictions with confidence scores\n\n3. Add model versioning:\n   - Store model checkpoints in `ml-service/models/food_classifier/`\n   - Add `model_version` field to responses\n   - Implement A/B testing capability by loading multiple model versions\n\n4. Extend nutrition database:\n   - Expand from current 6 items to 100+ common foods\n   - Structure: JSON file or SQLite database with USDA data\n   - Include serving size variations (small, medium, large)\n\nPseudo-code for classifier:\n```python\nclass FoodClassifier:\n    def __init__(self, model_path: str = None):\n        self.model = self._load_model(model_path)\n        self.classes = self._load_class_labels()\n    \n    def _load_model(self, path):\n        model = torchvision.models.efficientnet_b0(pretrained=True)\n        model.classifier[-1] = nn.Linear(1280, num_food_classes)\n        if path:\n            model.load_state_dict(torch.load(path))\n        model.eval()\n        return model\n    \n    async def classify(self, image: np.ndarray) -> List[Tuple[str, float]]:\n        tensor = self._preprocess(image)\n        with torch.no_grad():\n            outputs = self.model(tensor)\n            probs = torch.softmax(outputs, dim=1)\n        return self._get_top_k(probs, k=5)\n```",
        "testStrategy": "1. Unit tests for model loading and inference\n2. Test classification accuracy on held-out test set (target >80% top-5)\n3. Integration test: POST /api/food/analyze with real food images\n4. Performance test: Inference time <3s per image\n5. Test model fallback when GPU not available",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Build Health Metrics Mobile UI Screens",
        "description": "Create mobile screens for viewing and manually entering health metrics (RHR, HRV, sleep, recovery). Backend API is complete at /api/health-metrics.",
        "details": "1. Create new screens in `app/` directory:\n   - `app/health/index.tsx` - Health metrics dashboard/list\n   - `app/health/[id].tsx` - Detail view for specific metric\n   - `app/health/add.tsx` - Manual entry form\n\n2. Health Dashboard (`app/health/index.tsx`):\n   - Display today's key metrics in cards (RHR, HRV, Sleep, Recovery)\n   - Time range selector: Today, Week, Month\n   - Pull-to-refresh functionality\n   - Navigate to detail view on tap\n\n3. Metric Detail View (`app/health/[id].tsx`):\n   - Line chart showing metric over time (use react-native-chart-kit or Victory Native)\n   - Statistics: avg, min, max, trend arrow\n   - Data source indicator (Apple Health, Fitbit, Manual)\n   - Date range filter\n\n4. Manual Entry Form (`app/health/add.tsx`):\n   - Metric type picker (dropdown with all HealthMetricType enum values)\n   - Value input with unit display (bpm, ms, hours, %)\n   - Date/time picker (defaults to now)\n   - Source set to 'MANUAL'\n   - Validation: min/max ranges per metric type\n\n5. Create API client in `lib/api/health-metrics.ts`:\n```typescript\nexport const healthMetricsApi = {\n  getAll: (params: { startDate?: string; endDate?: string; metricType?: string }) => \n    apiClient.get('/health-metrics', { params }),\n  getById: (id: string) => apiClient.get(`/health-metrics/${id}`),\n  create: (data: CreateHealthMetricInput) => apiClient.post('/health-metrics', data),\n  getDailySummary: (date: string) => apiClient.get(`/health-metrics/daily/${date}`),\n}\n```\n\n6. Add navigation:\n   - Add 'Health' tab to bottom navigation in `app/(tabs)/_layout.tsx`\n   - Use health heart icon from @expo/vector-icons\n<info added on 2025-12-05T01:32:13.931Z>\nNow I have a comprehensive understanding of the codebase's styling patterns, typography, colors, and testing conventions. Let me provide the update text:\n\n7. Styling and UX Consistency Requirements:\n\nAll Health Metrics screens must follow the established design system in `lib/theme/colors.ts`:\n- Use `colors.background.primary` (#0F1419) as main background\n- Use `colors.background.tertiary` (#1E2330) for cards and surfaces\n- Use `colors.primary.main` (#8B5CF6) for interactive elements\n- Apply `gradients.primary` (purple-pink) for CTAs and active states\n- Text: `colors.text.primary` for headings, `colors.text.tertiary` for labels\n- Use `spacing` constants (xs:4, sm:8, md:16, lg:24, xl:32)\n- Apply `borderRadius` constants (sm:8, md:12, lg:16)\n- Use `typography.fontSize` and `typography.fontWeight` for consistent text styling\n- Import theme tokens: `import { colors, gradients, shadows, spacing, borderRadius, typography } from '@/lib/theme/colors'`\n\nMatch existing UX patterns from `app/(tabs)/index.tsx` and `app/add-meal.tsx`:\n- Cards with `borderWidth: 1, borderColor: colors.border.secondary`\n- Section titles: `fontSize: typography.fontSize['2xl']` or `lg`, `fontWeight: bold/semibold`\n- Form inputs: Height 48px, `backgroundColor: colors.background.tertiary`, `borderRadius: borderRadius.md`\n- Pull-to-refresh using `RefreshControl` with `tintColor={colors.primary.main}`\n- Loading states with `ActivityIndicator` using `colors.primary.main`\n- FAB pattern: 56x56 with LinearGradient and `shadows.xl`\n- SafeAreaView container with ScrollView using `showsVerticalScrollIndicator={false}`\n\n8. Comprehensive Test Requirements:\n\nCreate mobile component tests in `__tests__/` directory using react-native-testing-library:\n\nTest file structure:\n- `__tests__/screens/health/HealthDashboard.test.tsx`\n- `__tests__/screens/health/HealthMetricDetail.test.tsx`\n- `__tests__/screens/health/AddHealthMetric.test.tsx`\n- `__tests__/api/health-metrics.test.ts`\n\nRequired test coverage per screen:\n\nHealthDashboard tests:\n- Renders loading state with ActivityIndicator\n- Renders metric cards for RHR, HRV, Sleep, Recovery when data exists\n- Renders empty state when no health data available\n- Time range selector changes displayed data (Today/Week/Month)\n- Pull-to-refresh triggers API reload\n- Tapping metric card navigates to detail view\n- Error state rendering when API fails\n\nHealthMetricDetail tests:\n- Renders line chart with historical data\n- Displays statistics (avg, min, max, trend)\n- Shows correct data source indicator (Apple Health, Fitbit, Manual)\n- Date range filter updates chart data\n- Handles empty data gracefully\n- Loading and error states\n\nAddHealthMetric (Manual Entry) tests:\n- Metric type picker renders all HealthMetricType enum values\n- Value input accepts numeric input with correct units per type\n- Date/time picker defaults to current time\n- Source automatically set to MANUAL\n- Validation errors for out-of-range values (per metric type)\n- Required field validation\n- Successful submission calls API and navigates back\n- Cancel button discards changes and navigates back\n- Form disabled during submission\n\nAPI client tests (`lib/api/health-metrics.ts`):\n- Follow existing patterns from `__tests__/unit/api/food-analysis.test.ts`\n- Mock axios using `jest.mock('axios')`\n- Test getAll with various query params (startDate, endDate, metricType)\n- Test getById returns single metric\n- Test create sends correct payload and returns created metric\n- Test getDailySummary formats date correctly\n- Test error handling with proper error messages\n\nUse test patterns from existing tests:\n- Arrange, Act, Assert pattern\n- Mock dependencies with `jest.mock()`\n- Use `waitFor` for async assertions\n- Test user interactions with `fireEvent`\n</info added on 2025-12-05T01:32:13.931Z>",
        "testStrategy": "1. Component tests for each screen using react-native-testing-library\n2. Test form validation for manual entry\n3. Test API integration with mock server\n4. Visual regression tests for chart rendering\n5. Test pull-to-refresh behavior\n6. Test empty state when no health data exists",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create TypeScript types for health metrics in lib/types/health-metrics.ts",
            "description": "Define TypeScript interfaces and types for health metrics to be used across the mobile app, matching the backend API contracts.",
            "dependencies": [],
            "details": "Create `lib/types/health-metrics.ts` with the following types:\n\n1. **HealthMetricType enum** - Match the 28 types from `server/src/validation/schemas.ts` healthMetricTypeSchema: RESTING_HEART_RATE, HEART_RATE_VARIABILITY_SDNN, HEART_RATE_VARIABILITY_RMSSD, BLOOD_PRESSURE_SYSTOLIC, BLOOD_PRESSURE_DIASTOLIC, RESPIRATORY_RATE, OXYGEN_SATURATION, VO2_MAX, SLEEP_DURATION, DEEP_SLEEP_DURATION, REM_SLEEP_DURATION, SLEEP_EFFICIENCY, SLEEP_SCORE, STEPS, ACTIVE_CALORIES, TOTAL_CALORIES, EXERCISE_MINUTES, STANDING_HOURS, RECOVERY_SCORE, STRAIN_SCORE, READINESS_SCORE, BODY_FAT_PERCENTAGE, MUSCLE_MASS, BONE_MASS, WATER_PERCENTAGE, SKIN_TEMPERATURE, BLOOD_GLUCOSE, STRESS_LEVEL\n\n2. **HealthMetricSource type** - Match `server/src/validation/schemas.ts` healthMetricSourceSchema: 'apple_health' | 'fitbit' | 'garmin' | 'oura' | 'whoop' | 'manual'\n\n3. **HealthMetric interface** - Based on backend response: id, userId, metricType, value, unit, recordedAt, source, sourceId?, metadata?, createdAt, updatedAt\n\n4. **CreateHealthMetricInput interface** - Match `server/src/validation/schemas.ts` createHealthMetricSchema: metricType, value, unit, recordedAt (ISO string), source, sourceId?, metadata?\n\n5. **HealthMetricStats interface** - For stats endpoint: average, min, max, count, trend ('up' | 'down' | 'stable'), percentChange\n\n6. **TimeSeriesDataPoint interface** - For charts: date (string), value, source?\n\n7. **METRIC_CONFIG constant** - Unit and display info per metric type: { unit: string, displayName: string, minValue?: number, maxValue?: number, icon?: string }. Example: RESTING_HEART_RATE: { unit: 'bpm', displayName: 'Resting Heart Rate', minValue: 30, maxValue: 220 }",
            "status": "done",
            "testStrategy": null,
            "updatedAt": "2025-12-05T01:39:21.568Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Create health metrics API client in lib/api/health-metrics.ts",
            "description": "Implement API client functions to communicate with the backend health metrics endpoints, following the existing mealsApi pattern in lib/api/meals.ts.",
            "dependencies": [
              1
            ],
            "details": "Create `lib/api/health-metrics.ts` following the pattern from `lib/api/meals.ts`:\n\n```typescript\nimport api from './client';\nimport { HealthMetric, CreateHealthMetricInput, HealthMetricStats, TimeSeriesDataPoint, HealthMetricType, HealthMetricSource } from '../types/health-metrics';\n\nexport interface GetHealthMetricsParams {\n  metricType?: HealthMetricType;\n  startDate?: string;\n  endDate?: string;\n  source?: HealthMetricSource;\n  limit?: number;\n}\n\nexport const healthMetricsApi = {\n  // POST /health-metrics - Create single metric\n  async create(data: CreateHealthMetricInput): Promise<HealthMetric>,\n\n  // GET /health-metrics - Get all with optional filters\n  async getAll(params?: GetHealthMetricsParams): Promise<HealthMetric[]>,\n\n  // GET /health-metrics/:id - Get by ID\n  async getById(id: string): Promise<HealthMetric>,\n\n  // GET /health-metrics/latest/:metricType - Get latest value for a metric type\n  async getLatest(metricType: HealthMetricType): Promise<HealthMetric | null>,\n\n  // GET /health-metrics/timeseries/:metricType - Get time series data for charts\n  async getTimeSeries(metricType: HealthMetricType, startDate?: string, endDate?: string): Promise<TimeSeriesDataPoint[]>,\n\n  // GET /health-metrics/stats/:metricType - Get statistics (avg, min, max, trend)\n  async getStats(metricType: HealthMetricType, days?: number): Promise<HealthMetricStats>,\n\n  // GET /health-metrics/average/daily/:metricType - Get daily average\n  async getDailyAverage(metricType: HealthMetricType, date?: string): Promise<{ average: number; count: number }>,\n\n  // GET /health-metrics/average/weekly/:metricType - Get weekly average\n  async getWeeklyAverage(metricType: HealthMetricType): Promise<{ average: number; count: number }>,\n\n  // DELETE /health-metrics/:id - Delete metric\n  async delete(id: string): Promise<void>,\n};\n```\n\nUse the existing `api` client from `./client` which handles JWT auth token injection. Match the routes from `server/src/routes/healthMetricRoutes.ts`.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-05T01:39:52.642Z"
          },
          {
            "id": 3,
            "title": "Add Health tab to bottom navigation in app/(tabs)/_layout.tsx",
            "description": "Add a new 'Health' tab to the existing tab navigation using a heart icon, maintaining consistency with the current tab styling.",
            "dependencies": [],
            "details": "Modify `app/(tabs)/_layout.tsx` to add the Health tab:\n\n1. Add the 'heart.fill' SF Symbol to the MAPPING in `components/ui/IconSymbol.tsx`:\n```typescript\n'heart.fill': 'favorite',  // MaterialIcons mapping\n'person.fill': 'person',   // Already exists\n```\n\n2. Add new Tabs.Screen in `app/(tabs)/_layout.tsx` after the index tab and before profile:\n```typescript\n<Tabs.Screen\n  name=\"health\"\n  options={{\n    title: 'Health',\n    tabBarIcon: ({ color }) => <IconSymbol size={28} name=\"heart.fill\" color={color} />,\n  }}\n/>\n```\n\n3. Ensure the tab follows existing styling from tabBarStyle with:\n- `tabBarActiveTintColor: colors.primary.main` (purple #8B5CF6)\n- `tabBarInactiveTintColor: colors.text.disabled` (gray #6B7280)\n- Same height and padding as other tabs\n\n4. Export IconSymbolName type must include 'heart.fill' for TypeScript safety.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-05T01:40:18.178Z"
          },
          {
            "id": 4,
            "title": "Create Health Dashboard screen at app/(tabs)/health.tsx",
            "description": "Build the main Health Dashboard screen displaying today's key metrics (RHR, HRV, Sleep, Recovery) in cards with time range selector and pull-to-refresh.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create `app/(tabs)/health.tsx` following patterns from `app/(tabs)/index.tsx`:\n\n**Imports:**\n- React hooks: useState, useEffect, useCallback\n- Components: View, Text, StyleSheet, ScrollView, TouchableOpacity, RefreshControl, ActivityIndicator\n- expo-router: useRouter\n- SafeAreaView from react-native-safe-area-context\n- LinearGradient from expo-linear-gradient\n- Theme: colors, gradients, shadows, spacing, borderRadius, typography from '@/lib/theme/colors'\n- API: healthMetricsApi from '@/lib/api/health-metrics'\n- Types: HealthMetric, HealthMetricStats, METRIC_CONFIG from '@/lib/types/health-metrics'\n\n**State:**\n- metrics: Record<HealthMetricType, { latest: HealthMetric | null; stats: HealthMetricStats | null }>\n- timeRange: 'today' | 'week' | 'month' (default 'today')\n- isLoading: boolean, refreshing: boolean\n\n**Layout Structure:**\n1. Header with title \"Health\" and date (matches index.tsx greeting style: fontSize: typography.fontSize['3xl'], fontWeight: bold)\n2. Time Range Selector (horizontal buttons like meal type selector in add-meal.tsx)\n3. Metric Cards Grid (2x2) for: RESTING_HEART_RATE, HEART_RATE_VARIABILITY_SDNN, SLEEP_DURATION, RECOVERY_SCORE\n\n**Each Metric Card (TouchableOpacity):**\n- backgroundColor: colors.background.tertiary\n- borderWidth: 1, borderColor: colors.border.secondary\n- borderRadius: borderRadius.lg\n- padding: spacing.md\n- Icon (use Ionicons: heart-outline, pulse-outline, moon-outline, fitness-outline)\n- Label (colors.text.tertiary, fontSize: typography.fontSize.sm)\n- Value (colors.text.primary, fontSize: typography.fontSize['2xl'], fontWeight: bold)\n- Unit (colors.text.tertiary)\n- Trend indicator arrow (green up, red down, gray stable)\n- onPress: router.push(`/health/${metricType}`)\n\n**Pull-to-refresh:** Use RefreshControl with tintColor={colors.primary.main}\n\n**Loading State:** ActivityIndicator centered with colors.primary.main\n\n**Empty State:** \"No health data yet. Add your first metric!\" with button to /health/add",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-05T01:41:25.915Z"
          },
          {
            "id": 5,
            "title": "Create Metric Detail screen at app/health/[metricType].tsx",
            "description": "Build the detail view for a specific health metric showing historical line chart, statistics (avg, min, max, trend), date range filter, and data source indicator.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create `app/health/[metricType].tsx` as a dynamic route screen:\n\n**Imports:**\n- useLocalSearchParams from expo-router to get metricType param\n- LineChart from react-native-chart-kit (install if needed) or VictoryLine from victory-native\n- All theme imports from lib/theme/colors\n- healthMetricsApi and types\n\n**State:**\n- timeSeries: TimeSeriesDataPoint[] for chart data\n- stats: HealthMetricStats | null\n- dateRange: '7d' | '30d' | '90d' (default '30d')\n- isLoading: boolean\n\n**Layout:**\n1. **Header** with back button (TouchableOpacity with Ionicons chevron-back) and metric display name from METRIC_CONFIG\n\n2. **Date Range Selector** - Horizontal buttons matching add-meal.tsx mealTypeContainer style:\n   - 7 Days, 30 Days, 90 Days\n   - Active: LinearGradient with gradients.primary\n   - Inactive: backgroundColor: colors.background.tertiary\n\n3. **Line Chart** (full width, height ~200):\n   - backgroundColor: colors.background.tertiary\n   - Line color: colors.primary.main (#8B5CF6)\n   - Grid lines: colors.border.secondary\n   - Labels: colors.text.tertiary\n   - Data points from timeSeries API response\n\n4. **Statistics Card** (similar to macrosContainer in index.tsx):\n   - Three columns: Average, Minimum, Maximum\n   - Each shows value with unit\n   - fontSize: typography.fontSize.xl for values\n   - backgroundColor: colors.background.tertiary\n   - borderRadius: borderRadius.md\n\n5. **Trend Section:**\n   - Arrow icon (trending-up/down/minus from Ionicons)\n   - Percentage change text\n   - Color: status.success (green) for up, status.error (red) for down\n\n6. **Data Source Badge:**\n   - Icon per source (Apple Health, Fitbit, Manual, etc.)\n   - Text showing source name\n   - colors.text.tertiary styling\n\n**Chart Config (react-native-chart-kit):**\n```typescript\nchartConfig: {\n  backgroundColor: colors.background.tertiary,\n  backgroundGradientFrom: colors.background.tertiary,\n  backgroundGradientTo: colors.background.tertiary,\n  color: (opacity = 1) => `rgba(139, 92, 246, ${opacity})`, // primary.main\n  labelColor: (opacity = 1) => `rgba(156, 163, 175, ${opacity})`, // text.tertiary\n  strokeWidth: 2,\n}\n```",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-05T01:43:39.003Z"
          },
          {
            "id": 6,
            "title": "Create Manual Entry form at app/health/add.tsx",
            "description": "Build the form for manually entering health metrics with metric type picker, value input with dynamic units, date/time picker, and validation for min/max ranges per metric type.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create `app/health/add.tsx` following the pattern from `app/add-meal.tsx`:\n\n**Imports:**\n- useState, useEffect from react\n- All RN components: View, Text, TextInput, TouchableOpacity, StyleSheet, ScrollView, KeyboardAvoidingView, Platform, ActivityIndicator\n- useRouter from expo-router\n- SafeAreaView, LinearGradient, Ionicons\n- DateTimePicker from @react-native-community/datetimepicker (or expo-date-time-picker)\n- Picker from @react-native-picker/picker\n- healthMetricsApi, CreateHealthMetricInput, HealthMetricType, METRIC_CONFIG\n- colors, gradients, spacing, borderRadius, typography from theme\n- showAlert from '@/lib/utils/alert'\n- getErrorMessage from '@/lib/utils/errorHandling'\n\n**State:**\n- metricType: HealthMetricType (default 'RESTING_HEART_RATE')\n- value: string (for TextInput)\n- recordedAt: Date (default new Date())\n- isLoading: boolean\n- showDatePicker: boolean\n- errors: { value?: string }\n\n**Layout (match add-meal.tsx structure):**\n1. **Header** - Same as add-meal: Cancel (left), \"Add Health Metric\" (center), Save (right)\n   - Cancel: text style, color: colors.text.secondary\n   - Save: text style, color: colors.primary.main, disabled when isLoading\n\n2. **Metric Type Picker Section:**\n   - Label: \"Metric Type\" (styles.sectionTitle)\n   - Dropdown picker with all 28 HealthMetricType values\n   - Group by category: Cardiovascular, Sleep, Activity, Recovery, Body Composition\n   - Display friendly names from METRIC_CONFIG.displayName\n\n3. **Value Input Section:**\n   - Label: \"Value ({unit})\" - dynamically show unit from METRIC_CONFIG[metricType].unit\n   - TextInput with keyboardType=\"decimal-pad\"\n   - Height 48px, backgroundColor: colors.background.tertiary\n   - Validation message below if out of range (colors.status.error)\n\n4. **Date/Time Picker Section:**\n   - Label: \"Recorded At\"\n   - TouchableOpacity showing formatted date/time\n   - Opens DateTimePicker modal\n   - Default to current time\n\n5. **Source Badge** (non-editable):\n   - Shows \"Manual\" with checkmark icon\n   - Subtle styling: colors.special.highlight background\n\n**Validation:**\n- Value required and numeric\n- Check against METRIC_CONFIG[metricType].minValue and maxValue\n- Show inline error: \"Value must be between {min} and {max} {unit}\"\n\n**handleSave:**\n```typescript\nconst data: CreateHealthMetricInput = {\n  metricType,\n  value: parseFloat(value),\n  unit: METRIC_CONFIG[metricType].unit,\n  recordedAt: recordedAt.toISOString(),\n  source: 'manual',\n};\nawait healthMetricsApi.create(data);\nshowAlert('Success', 'Health metric added!', [{ text: 'OK', onPress: () => router.back() }]);\n```",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-05T01:45:06.446Z"
          },
          {
            "id": 7,
            "title": "Write unit tests for health-metrics API client",
            "description": "Create comprehensive unit tests for lib/api/health-metrics.ts following the existing test patterns from __tests__/unit/api/food-analysis.test.ts.",
            "dependencies": [
              2
            ],
            "details": "Create `__tests__/unit/api/health-metrics.test.ts`:\n\n**Setup:**\n```typescript\nimport axios from 'axios';\nimport { healthMetricsApi } from '@/lib/api/health-metrics';\nimport { HealthMetric, HealthMetricType, HealthMetricStats, TimeSeriesDataPoint } from '@/lib/types/health-metrics';\n\njest.mock('axios');\nconst mockedAxios = axios as jest.Mocked<typeof axios>;\n```\n\n**Test Fixtures:**\n```typescript\nconst mockHealthMetric: HealthMetric = {\n  id: 'metric-1',\n  userId: 'user-1',\n  metricType: 'RESTING_HEART_RATE',\n  value: 62,\n  unit: 'bpm',\n  recordedAt: '2024-01-15T08:00:00Z',\n  source: 'manual',\n  createdAt: '2024-01-15T08:00:00Z',\n  updatedAt: '2024-01-15T08:00:00Z',\n};\n\nconst mockStats: HealthMetricStats = {\n  average: 65,\n  min: 58,\n  max: 72,\n  count: 30,\n  trend: 'down',\n  percentChange: -3.5,\n};\n```\n\n**Test Cases:**\n\n1. **create():**\n   - Should successfully create a health metric\n   - Should send correct payload format to POST /health-metrics\n   - Should handle validation errors (400)\n   - Should handle auth errors (401)\n\n2. **getAll():**\n   - Should return array of metrics\n   - Should pass query params (metricType, startDate, endDate, source, limit)\n   - Should handle empty results\n   - Should handle network errors\n\n3. **getById():**\n   - Should return single metric by ID\n   - Should handle 404 not found\n\n4. **getLatest():**\n   - Should return latest metric for type\n   - Should return null when no metrics exist\n\n5. **getTimeSeries():**\n   - Should return array of data points for chart\n   - Should pass date range params\n   - Should handle empty data gracefully\n\n6. **getStats():**\n   - Should return stats with average, min, max, trend\n   - Should pass days param\n   - Should handle 404 when no data\n\n7. **getDailyAverage() and getWeeklyAverage():**\n   - Should return average and count\n   - Should handle date param for daily\n\n8. **delete():**\n   - Should successfully delete metric\n   - Should handle 404 errors\n\n**Pattern:** Use Arrange, Act, Assert. Mock `api.get`, `api.post`, `api.delete` from the client module.",
            "status": "done",
            "testStrategy": "Run with `npm test __tests__/unit/api/health-metrics.test.ts`. Verify all API methods are tested with success and error cases. Check coverage with `npm run test:coverage`.",
            "parentId": "undefined",
            "updatedAt": "2025-12-05T01:46:30.103Z"
          },
          {
            "id": 8,
            "title": "Write component tests for Health screens",
            "description": "Create comprehensive component tests for HealthDashboard, HealthMetricDetail, and AddHealthMetric screens using react-native-testing-library.",
            "dependencies": [
              4,
              5,
              6
            ],
            "details": "Create test files in `__tests__/screens/health/` directory:\n\n**1. __tests__/screens/health/HealthDashboard.test.tsx:**\n```typescript\nimport React from 'react';\nimport { render, fireEvent, waitFor } from '@testing-library/react-native';\nimport HealthDashboard from '@/app/(tabs)/health';\nimport { healthMetricsApi } from '@/lib/api/health-metrics';\n\njest.mock('@/lib/api/health-metrics');\njest.mock('expo-router', () => ({ useRouter: () => ({ push: jest.fn() }) }));\njest.mock('@/lib/context/AuthContext', () => ({ useAuth: () => ({ user: { id: '1', name: 'Test' } }) }));\n```\n\nTest cases:\n- Renders loading state with ActivityIndicator initially\n- Renders metric cards when data loads successfully\n- Renders empty state when no health data available\n- Time range selector updates displayed data (Today/Week/Month)\n- Pull-to-refresh triggers API reload (test RefreshControl onRefresh)\n- Tapping metric card calls router.push with correct metric type\n- Error state renders when API fails\n\n**2. __tests__/screens/health/HealthMetricDetail.test.tsx:**\n\nTest cases:\n- Renders line chart with historical data points\n- Displays statistics (avg, min, max, trend arrow, percentage)\n- Shows correct data source indicator icon/text\n- Date range filter buttons update chart data (7d/30d/90d)\n- Handles empty data gracefully with message\n- Loading state shows ActivityIndicator\n- Error state with retry button\n\n**3. __tests__/screens/health/AddHealthMetric.test.tsx:**\n\nTest cases:\n- Metric type picker renders all HealthMetricType enum values\n- Value input accepts numeric input and shows correct unit dynamically\n- Date/time picker defaults to current time and opens modal\n- Source automatically displays \"Manual\"\n- Shows validation error for out-of-range values (test per metric type bounds)\n- Shows required field validation when value empty\n- Successful submission calls API and navigates back\n- Cancel button navigates back without saving\n- Form inputs disabled during submission (isLoading state)\n- Shows loading indicator on Save button during submission\n\n**Common Mocks:**\n- Mock @react-native-community/datetimepicker\n- Mock @react-native-picker/picker\n- Mock react-native-chart-kit or victory-native\n- Mock expo-linear-gradient",
            "status": "done",
            "testStrategy": "Run with `npm test __tests__/screens/health/`. Verify all user interactions are tested. Use `fireEvent` for button presses and text input. Use `waitFor` for async operations. Target 80%+ coverage for all three screens.",
            "parentId": "undefined",
            "updatedAt": "2025-12-05T01:46:30.166Z"
          }
        ],
        "updatedAt": "2025-12-05T01:59:24.616Z"
      },
      {
        "id": 4,
        "title": "Build Activity Tracking Mobile UI Screens",
        "description": "Create mobile screens for viewing and manually logging activities. Backend API is complete at /api/activities.",
        "details": "1. Create new screens in `app/` directory:\n   - `app/activity/index.tsx` - Activity list/history\n   - `app/activity/[id].tsx` - Activity detail view\n   - `app/activity/add.tsx` - Manual activity entry form\n\n2. Activity List (`app/activity/index.tsx`):\n   - Weekly summary card: total minutes, calories, workout count\n   - Filter by activity type (All, Cardio, Strength, Flexibility)\n   - List of recent activities with icon, duration, calories\n   - Floating action button to add new activity\n   - Pull-to-refresh\n\n3. Activity Detail View (`app/activity/[id].tsx`):\n   - Display all activity fields: type, duration, intensity, calories\n   - Heart rate data if available (avg, max)\n   - Distance and steps for applicable activities\n   - Notes field\n   - Edit/Delete buttons\n\n4. Manual Entry Form (`app/activity/add.tsx`):\n   - Activity type picker (21 types from ActivityType enum)\n   - Intensity picker (Low, Moderate, High, Maximum)\n   - Duration input (hours:minutes picker)\n   - Date/time pickers for start time\n   - Optional fields: calories, heart rate, distance, notes\n   - Validation: duration > 0, end time > start time\n\n5. Create API client in `lib/api/activities.ts`:\n```typescript\nexport const activitiesApi = {\n  getAll: (params?: { activityType?: string; startDate?: string }) =>\n    apiClient.get('/activities', { params }),\n  getById: (id: string) => apiClient.get(`/activities/${id}`),\n  create: (data: CreateActivityInput) => apiClient.post('/activities', data),\n  update: (id: string, data: Partial<CreateActivityInput>) =>\n    apiClient.put(`/activities/${id}`, data),\n  delete: (id: string) => apiClient.delete(`/activities/${id}`),\n  getWeeklySummary: () => apiClient.get('/activities/weekly-summary'),\n}\n```\n\n6. Add activity icons mapping for different activity types",
        "testStrategy": "1. Component tests for each screen\n2. Test form validation (duration, time constraints)\n3. Test activity type filtering\n4. Test CRUD operations with mock API\n5. Test weekly summary calculation display\n6. Test edit/delete flows with confirmation dialogs",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Implement Apple HealthKit Integration",
        "description": "Enable automatic sync of comprehensive health data from Apple HealthKit including cardiovascular metrics (RHR, Heart Rate, HRV SDNN/RMSSD), sleep quality metrics (duration, deep sleep, REM, efficiency, score), respiratory data (respiratory rate, oxygen saturation), and VO2Max.",
        "status": "done",
        "dependencies": [
          "3",
          "4"
        ],
        "priority": "medium",
        "details": "1. Install and configure react-native-health (recommended for Expo managed workflow):\n   - Add `react-native-health` to package.json dependencies\n   - Configure `app.json` with NSHealthShareUsageDescription and NSHealthUpdateUsageDescription\n   - Add HealthKit entitlement to iOS build configuration\n   - Request HealthKit permissions on iOS for all metric types\n\n2. **Schema Consideration**: The existing Prisma HealthMetricType enum in `server/prisma/schema.prisma` already supports:\n   - Cardiovascular: `RESTING_HEART_RATE`, `HEART_RATE_VARIABILITY_SDNN`, `HEART_RATE_VARIABILITY_RMSSD`\n   - Respiratory: `RESPIRATORY_RATE`, `OXYGEN_SATURATION`, `VO2_MAX`\n   - Sleep: `SLEEP_DURATION`, `DEEP_SLEEP_DURATION`, `REM_SLEEP_DURATION`, `SLEEP_EFFICIENCY`, `SLEEP_SCORE`\n   - NOTE: Consider adding `HEART_RATE` (instantaneous/average HR, separate from resting) if needed for workout HR data\n\n3. Create health sync service in `lib/services/healthkit.ts`:\n```typescript\nexport interface HealthKitConfig {\n  permissions: {\n    read: HealthKitPermission[];\n    write?: HealthKitPermission[];\n  };\n}\n\nexport const healthKitService = {\n  // Initialize and request permissions\n  requestPermissions: () => Promise<boolean>,\n  isAvailable: () => Promise<boolean>,\n  \n  // Sync cardiovascular data\n  syncCardiovascularMetrics: (startDate: Date, endDate: Date) => Promise<HealthMetric[]>,\n  // - HKQuantityTypeIdentifierRestingHeartRate → RESTING_HEART_RATE\n  // - HKQuantityTypeIdentifierHeartRate → instantaneous HR samples\n  // - HKQuantityTypeIdentifierHeartRateVariabilitySDNN → HEART_RATE_VARIABILITY_SDNN\n  // - HKQuantityTypeIdentifier.heartRateVariabilityRMSSD (if available)\n  \n  // Sync respiratory data\n  syncRespiratoryMetrics: (startDate: Date, endDate: Date) => Promise<HealthMetric[]>,\n  // - HKQuantityTypeIdentifierRespiratoryRate → RESPIRATORY_RATE\n  // - HKQuantityTypeIdentifierOxygenSaturation → OXYGEN_SATURATION\n  // - HKQuantityTypeIdentifierVO2Max → VO2_MAX\n  \n  // Sync sleep data\n  syncSleepMetrics: (startDate: Date, endDate: Date) => Promise<HealthMetric[]>,\n  // - HKCategoryTypeIdentifierSleepAnalysis → parse into:\n  //   - SLEEP_DURATION (total sleep time)\n  //   - DEEP_SLEEP_DURATION (deep/core sleep stages)\n  //   - REM_SLEEP_DURATION (REM stages)\n  //   - SLEEP_EFFICIENCY (time asleep / time in bed)\n  //   - SLEEP_SCORE (if available from source)\n  \n  // Sync activity data\n  syncActivityMetrics: (startDate: Date, endDate: Date) => Promise<HealthMetric[]>,\n  // - HKQuantityTypeIdentifierStepCount → STEPS\n  // - HKQuantityTypeIdentifierActiveEnergyBurned → ACTIVE_CALORIES\n  // - HKWorkoutType → Activity model with exercise HR data\n  \n  // Background sync\n  setupBackgroundSync: () => void,\n}\n```\n\n4. HealthKit type identifiers mapping:\n```typescript\nconst HEALTHKIT_TYPE_MAP = {\n  // Cardiovascular\n  HKQuantityTypeIdentifierRestingHeartRate: 'RESTING_HEART_RATE',\n  HKQuantityTypeIdentifierHeartRateVariabilitySDNN: 'HEART_RATE_VARIABILITY_SDNN',\n  // Note: RMSSD might need manual calculation from RR intervals\n  \n  // Respiratory\n  HKQuantityTypeIdentifierRespiratoryRate: 'RESPIRATORY_RATE',\n  HKQuantityTypeIdentifierOxygenSaturation: 'OXYGEN_SATURATION',\n  HKQuantityTypeIdentifierVO2Max: 'VO2_MAX',\n  \n  // Sleep (requires parsing HKCategoryTypeIdentifierSleepAnalysis)\n  // Sleep stages: inBed, asleepUnspecified, awake, asleepCore, asleepDeep, asleepREM\n  \n  // Activity\n  HKQuantityTypeIdentifierStepCount: 'STEPS',\n  HKQuantityTypeIdentifierActiveEnergyBurned: 'ACTIVE_CALORIES',\n};\n```\n\n5. Implement data transformation layer:\n   - Convert HealthKit units to API units (bpm, ms, %, steps, kcal, etc.)\n   - Match existing Zod validation schemas in `server/src/validation/schemas.ts`\n   - Use source: 'apple_health' to match healthMetricSourceSchema\n   - Include device metadata: {device: \"Apple Watch\", quality: \"high\"}\n\n6. Create sync flow:\n   - Initial sync: Fetch last 30 days of data on first connect\n   - Incremental sync: Fetch data since last sync timestamp\n   - Store lastSyncTimestamp in Expo SecureStore (per metric type for efficiency)\n   - Batch API calls using bulkCreateHealthMetricsSchema (50 items per request)\n   - Handle timezone conversions (HealthKit returns local time, API expects UTC)\n\n7. Handle data deduplication:\n   - Use existing (userId, metricType, recordedAt, source) unique constraint in schema\n   - Server handles conflicts via upsert\n   - Store sourceId from HealthKit sample UUID for traceability\n\n8. Add sync UI in profile settings (app/profile.tsx or new app/settings/health.tsx):\n   - Connect/Disconnect Apple Health button\n   - Permission status for each metric category\n   - Last sync timestamp display (per category)\n   - Manual sync button with progress indicator\n   - Sync status indicator (syncing, synced, error)\n   - Data preview showing recently synced metrics\n\n9. Handle background sync (future enhancement):\n   - Configure iOS background fetch capability\n   - Sync when app becomes active via AppState listener\n   - Respect battery and data usage settings\n   - Consider using HealthKit's HKObserverQuery for real-time updates",
        "testStrategy": "1. Unit tests for HealthKit service:\n   - Mock react-native-health module for simulator testing\n   - Test permission request flow and error handling\n   - Test data transformation for each metric type (HK format → API format)\n   - Test unit conversions (HK units → standard units)\n\n2. Test cardiovascular data sync:\n   - Mock RHR samples → verify RESTING_HEART_RATE records\n   - Mock HRV samples → verify HEART_RATE_VARIABILITY_SDNN records\n   - Test edge cases: missing data, invalid values\n\n3. Test respiratory data sync:\n   - Mock respiratory rate → verify RESPIRATORY_RATE records\n   - Mock SpO2 → verify OXYGEN_SATURATION records\n   - Mock VO2Max → verify VO2_MAX records\n\n4. Test sleep data parsing:\n   - Mock sleep analysis categories → verify correct stage classification\n   - Test sleep efficiency calculation (time asleep / time in bed)\n   - Test sleep duration aggregation across fragmented sleep\n\n5. Test sync error handling and retry logic:\n   - Network errors during bulk upload\n   - Partial failures in batch operations\n   - Permission denied scenarios\n\n6. Test deduplication with existing data:\n   - Re-sync same data → verify no duplicates\n   - Test sourceId matching\n\n7. Test UI state updates during sync:\n   - Loading states\n   - Progress indication\n   - Error display\n\n8. Manual testing on physical device:\n   - Test with real Apple Watch data\n   - Verify data accuracy against Health app\n   - Test permission prompts\n   - Test background sync behavior",
        "subtasks": [
          {
            "id": 1,
            "title": "Install and configure react-native-health package",
            "description": "Add react-native-health dependency and configure iOS build settings with proper entitlements and Info.plist descriptions",
            "dependencies": [],
            "details": "Install react-native-health via npm/yarn. Update app.json with NSHealthShareUsageDescription explaining why the app needs read access to health data. Add HealthKit entitlement. Configure iOS build to include HealthKit framework. Test that the package builds correctly on iOS simulator/device.",
            "status": "done",
            "testStrategy": "Verify package installs without errors. Confirm iOS build succeeds. Check Info.plist contains correct health usage descriptions.",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T20:30:33.391Z"
          },
          {
            "id": 2,
            "title": "Create HealthKit permission management system",
            "description": "Implement permission request flow for all required HealthKit data types including cardiovascular, respiratory, and sleep metrics",
            "dependencies": [
              1
            ],
            "details": "Create lib/services/healthkit/permissions.ts. Define permission sets for each metric category. Implement isAvailable() check for HealthKit. Implement requestPermissions() with granular permission requests. Handle partial permission grants gracefully. Store permission status in context/state.",
            "status": "done",
            "testStrategy": "Mock HealthKit permissions. Test all permission states (granted, denied, not determined). Test partial permission scenarios.",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T20:30:33.786Z"
          },
          {
            "id": 3,
            "title": "Implement cardiovascular metrics sync (RHR, HR, HRV)",
            "description": "Create sync functions for Resting Heart Rate, Heart Rate samples, and Heart Rate Variability (SDNN and RMSSD)",
            "dependencies": [
              2
            ],
            "details": "Implement syncCardiovascularMetrics() in healthkit.ts. Query HKQuantityTypeIdentifierRestingHeartRate for RHR. Query HKQuantityTypeIdentifierHeartRateVariabilitySDNN for HRV. Transform HealthKit samples to match HealthMetric API format. Handle unit conversions (HK returns bpm/ms). Include device metadata from sample source.",
            "status": "done",
            "testStrategy": "Mock HK cardiovascular queries. Verify correct transformation to RESTING_HEART_RATE and HEART_RATE_VARIABILITY_SDNN types. Test unit handling.",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T20:30:33.979Z"
          },
          {
            "id": 4,
            "title": "Implement respiratory metrics sync (respiratory rate, SpO2, VO2Max)",
            "description": "Create sync functions for respiratory rate, oxygen saturation, and VO2Max data from HealthKit",
            "dependencies": [
              2
            ],
            "details": "Implement syncRespiratoryMetrics() in healthkit.ts. Query HKQuantityTypeIdentifierRespiratoryRate, HKQuantityTypeIdentifierOxygenSaturation, and HKQuantityTypeIdentifierVO2Max. Transform to RESPIRATORY_RATE, OXYGEN_SATURATION, and VO2_MAX metric types. Handle different sample frequencies (VO2Max is less frequent).",
            "status": "done",
            "testStrategy": "Mock HK respiratory queries. Verify correct transformation to API format. Test handling of sparse VO2Max data.",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T20:30:34.209Z"
          },
          {
            "id": 5,
            "title": "Implement sleep metrics sync with stage classification",
            "description": "Create sync function for sleep analysis including duration, deep sleep, REM, and efficiency calculations",
            "dependencies": [
              2
            ],
            "details": "Implement syncSleepMetrics() in healthkit.ts. Query HKCategoryTypeIdentifierSleepAnalysis. Parse sleep stages (asleepCore→DEEP_SLEEP, asleepDeep→DEEP_SLEEP, asleepREM→REM_SLEEP). Calculate total SLEEP_DURATION. Calculate SLEEP_EFFICIENCY (asleep time / in bed time). Handle fragmented sleep sessions.",
            "status": "done",
            "testStrategy": "Mock HK sleep analysis with various stage combinations. Verify correct duration calculations. Test efficiency calculation accuracy. Test fragmented sleep handling.",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T20:30:34.351Z"
          },
          {
            "id": 6,
            "title": "Implement activity metrics sync (steps, active calories)",
            "description": "Create sync function for daily activity data including step count and active energy burned",
            "dependencies": [
              2
            ],
            "details": "Implement syncActivityMetrics() in healthkit.ts. Query HKQuantityTypeIdentifierStepCount and HKQuantityTypeIdentifierActiveEnergyBurned. Aggregate daily totals. Transform to STEPS and ACTIVE_CALORIES metric types. Handle timezone boundaries for daily aggregation.",
            "status": "done",
            "testStrategy": "Mock HK activity queries. Verify daily aggregation logic. Test timezone handling for day boundaries.",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T20:30:34.528Z"
          },
          {
            "id": 7,
            "title": "Create batch sync orchestration with API integration",
            "description": "Implement the main sync orchestration that coordinates all metric syncs and uploads to the backend API",
            "dependencies": [
              3,
              4,
              5,
              6
            ],
            "details": "Create syncAllHealthData() coordinator function. Implement incremental sync using stored lastSyncTimestamp from SecureStore. Batch API uploads using bulkCreateHealthMetricsSchema (50 items per request). Handle partial failures and retry logic. Update lastSyncTimestamp per metric category on success.",
            "status": "done",
            "testStrategy": "Test full sync orchestration flow. Verify batch chunking at 50 items. Test incremental sync with stored timestamps. Test error handling and retry.",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T20:30:34.685Z"
          },
          {
            "id": 8,
            "title": "Build HealthKit settings UI with sync controls",
            "description": "Create the user interface for managing HealthKit connection, viewing sync status, and triggering manual syncs",
            "dependencies": [
              7
            ],
            "details": "Create app/settings/health.tsx screen or add section to app/profile.tsx. Display Connect/Disconnect Apple Health button. Show permission status per metric category with toggle indicators. Display last sync timestamp and synced data counts. Add manual Sync Now button with progress indicator. Show sync status (syncing/synced/error) with appropriate feedback.",
            "status": "done",
            "testStrategy": "Test UI component rendering. Test connect/disconnect flow. Test sync button interaction and loading states. Test error state display.",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T20:30:34.823Z"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Break down the Apple HealthKit integration into implementation phases:\n\n1. **Library Setup & Configuration**: Install react-native-health or expo-health-connect, configure iOS entitlements in app.json (NSHealthShareUsageDescription), and set up the Expo plugin. Research which library works best with Expo SDK 52.\n\n2. **HealthKit Service Core**: Create `lib/services/healthkit.ts` with typed interfaces matching the existing TypeScript patterns in `lib/types/index.ts`. Implement the base service structure with permission request methods.\n\n3. **Data Fetching Implementation**: Implement data fetching for each metric type mapping HealthKit identifiers to the existing HealthMetricType enum (RESTING_HEART_RATE, HEART_RATE_VARIABILITY_SDNN, SLEEP_DURATION, STEPS, ACTIVE_CALORIES). Note: Add ACTIVE_HEART_RATE to schema.prisma for instantaneous HR.\n\n4. **Activity Sync Implementation**: Map HKWorkoutType to the existing ActivityType enum (RUNNING, CYCLING, SWIMMING, etc.) in schema.prisma. Handle activity data transformation.\n\n5. **Sync Logic & State Management**: Implement initial sync (30 days), incremental sync with lastSyncTimestamp stored in SecureStore (pattern from lib/api/client.ts), batch API calls (50 items/request), and leverage the existing bulk endpoint at `/api/health-metrics/bulk`.\n\n6. **Profile UI Integration**: Extend the existing `app/(tabs)/profile.tsx` with a Health Integration section. Add Connect/Disconnect Apple Health button, sync status indicators, last sync timestamp display, and manual sync button following the existing design patterns.\n\n7. **Testing & Error Handling**: Mock HealthKit data for simulator, test permission flows, data transformation, sync error handling/retry logic, and UI state updates. Follow existing error handling patterns in lib/utils/errorHandling.ts.",
        "updatedAt": "2025-12-11T20:30:34.823Z"
      },
      {
        "id": 6,
        "title": "Train and Deploy LSTM Models for Health Predictions",
        "description": "Train LSTM models for RHR and HRV prediction using the existing model architecture in ml-service/app/ml_models/lstm.py and make them production-ready.",
        "details": "1. Create training pipeline in `ml-service/app/services/model_training.py`:\n   - Already has TrainModelRequest/Response schemas\n   - Implement data loading from database\n   - Create training/validation split (80/20)\n   - Add early stopping with patience=10\n   - Save model checkpoints and metadata\n\n2. Training data preparation:\n   - Use FeatureEngineeringService to generate features\n   - Create sliding window sequences (30-day windows)\n   - Normalize features using StandardScaler (save scaler with model)\n   - Handle missing data: forward-fill then drop incomplete sequences\n\n3. Training configuration:\n   - RHR model: hidden_dim=128, num_layers=2, dropout=0.2\n   - HRV model: hidden_dim=128, num_layers=2, dropout=0.2\n   - Batch size: 32, learning rate: 0.001\n   - Use Adam optimizer, MSE loss\n   - Train for max 100 epochs with early stopping\n\n4. Model evaluation metrics:\n   - MAE (Mean Absolute Error)\n   - RMSE (Root Mean Square Error)\n   - R² score (>0.5 for production)\n   - MAPE (Mean Absolute Percentage Error, <15% for production)\n\n5. Update PredictionService in `ml-service/app/services/prediction.py`:\n   - Load trained model from disk\n   - Load corresponding scaler\n   - Prepare input sequence from recent features\n   - Run inference and denormalize output\n   - Calculate confidence intervals\n\n6. Model storage structure:\n```\nml-service/models/\n  {user_id}_{metric}_{timestamp}/\n    model.pt              # PyTorch model weights\n    scaler.pkl           # Feature scaler\n    metadata.pkl         # Training config and metrics\n```\n\n7. Add minimum data requirements:\n   - At least 30 days of health data\n   - At least 21 days of nutrition data\n   - Check requirements before training",
        "testStrategy": "1. Unit tests for data preparation pipeline\n2. Test training with synthetic data (verify loss decreases)\n3. Test model save/load roundtrip\n4. Test prediction accuracy on held-out test set\n5. Integration test: full train -> predict flow\n6. Test minimum data requirement validation\n7. Test early stopping triggers correctly",
        "priority": "high",
        "dependencies": [
          "3",
          "5"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Create Predictions Visualization Mobile UI",
        "description": "Build mobile screens to display ML predictions (RHR, HRV forecasts) with confidence intervals and historical context.",
        "details": "1. Create new screens:\n   - `app/predictions/index.tsx` - Predictions dashboard\n   - `app/predictions/[metric].tsx` - Detailed prediction view\n\n2. Predictions Dashboard (`app/predictions/index.tsx`):\n   - Card for each predictable metric (RHR, HRV)\n   - Display: predicted value, confidence score, direction indicator\n   - Comparison to 30-day average\n   - 'No prediction available' state if model not trained\n   - Pull-to-refresh to get latest predictions\n\n3. Detailed Prediction View (`app/predictions/[metric].tsx`):\n   - Chart showing:\n     - Historical values (last 30 days)\n     - Predicted value for tomorrow\n     - Confidence interval as shaded region\n   - Interpretation text (AI-generated explanation)\n   - Recommendation based on prediction\n   - Feature importance breakdown (what drove this prediction)\n\n4. Create API client in `lib/api/predictions.ts`:\n```typescript\nexport const predictionsApi = {\n  predict: (metric: string, targetDate: string) =>\n    apiClient.post('/api/predictions/predict', { metric, target_date: targetDate }),\n  batchPredict: (metrics: string[], targetDate: string) =>\n    apiClient.post('/api/predictions/batch-predict', { metrics, target_date: targetDate }),\n  listModels: () => apiClient.get('/api/predictions/models'),\n}\n```\n\n5. Chart implementation:\n   - Use Victory Native or react-native-chart-kit\n   - Line chart for historical + predicted\n   - Shaded area for confidence interval\n   - Animate prediction point\n\n6. Handle states:\n   - Loading: Show skeleton\n   - No model trained: Show CTA to collect more data\n   - Prediction available: Show full UI\n   - Error: Show error message with retry",
        "testStrategy": "1. Component tests for dashboard and detail screens\n2. Test chart rendering with mock data\n3. Test loading/error/empty states\n4. Test confidence interval visualization\n5. Test API integration with mock responses\n6. Snapshot tests for consistent UI",
        "priority": "medium",
        "dependencies": [
          "6"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Implement ML Insights Engine and Recommendations",
        "description": "Build the insights generation system that analyzes correlations and generates personalized nutrition recommendations stored in MLInsight model.",
        "details": "1. Create insights service in `ml-service/app/services/insights_engine.py`:\n```python\nclass InsightsEngine:\n    async def generate_insights(self, user_id: str) -> List[MLInsight]:\n        correlations = await self._get_significant_correlations(user_id)\n        predictions = await self._get_recent_predictions(user_id)\n        anomalies = await self._detect_anomalies(user_id)\n        \n        insights = []\n        insights.extend(self._correlation_insights(correlations))\n        insights.extend(self._prediction_insights(predictions))\n        insights.extend(self._anomaly_insights(anomalies))\n        insights.extend(self._goal_progress_insights(user_id))\n        \n        return self._prioritize_and_limit(insights, max_insights=5)\n```\n\n2. Insight types to implement:\n   - CORRELATION: 'Your protein intake correlates with better HRV (+0.65)'\n   - PREDICTION: 'Tomorrow's RHR is predicted higher than average'\n   - ANOMALY: 'Your sleep duration last night was unusually low'\n   - RECOMMENDATION: 'Try eating dinner earlier to improve sleep quality'\n   - GOAL_PROGRESS: 'You're 80% of the way to your protein goal this week'\n   - PATTERN_DETECTED: 'You tend to eat more carbs on weekends'\n\n3. Correlation-based recommendations:\n   - Use CorrelationEngineService to find significant correlations\n   - Filter by correlation strength (|r| > 0.5)\n   - Generate natural language recommendations\n   - Example: If protein ↔ HRV has r=0.7, recommend 'Increasing protein may improve your HRV'\n\n4. Anomaly detection:\n   - Z-score based detection (>2 std from 30-day mean)\n   - Detect unusual: meal timing, calorie intake, sleep duration\n   - Generate alerts for negative anomalies\n\n5. Create API endpoints in `ml-service/app/api/insights.py`:\n   - GET /api/insights - List user's active insights\n   - POST /api/insights/generate - Trigger insight generation\n   - PUT /api/insights/{id}/viewed - Mark as viewed\n   - PUT /api/insights/{id}/dismissed - Dismiss insight\n   - PUT /api/insights/{id}/feedback - Submit helpful/not helpful\n\n6. Store insights in database using MLInsight model (already defined in Prisma schema)",
        "testStrategy": "1. Unit tests for each insight type generator\n2. Test insight prioritization logic\n3. Test anomaly detection thresholds\n4. Test natural language generation\n5. Integration test: end-to-end insight generation\n6. Test user feedback tracking\n7. Test insight expiration handling",
        "priority": "medium",
        "dependencies": [
          "6"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Build Insights Feed Mobile UI",
        "description": "Create mobile screens to display ML-generated insights, recommendations, and allow user feedback.",
        "details": "1. Create new screens:\n   - `app/insights/index.tsx` - Insights feed/dashboard\n   - `app/insights/[id].tsx` - Detailed insight view\n\n2. Insights Feed (`app/insights/index.tsx`):\n   - List of insight cards sorted by priority and recency\n   - Card components per insight type:\n     - Correlation: Show correlation strength badge\n     - Prediction: Show predicted value and arrow\n     - Anomaly: Show warning indicator\n     - Recommendation: Show actionable tip\n   - Swipe to dismiss functionality\n   - Pull-to-refresh to generate new insights\n   - Empty state: 'Keep logging meals to unlock insights'\n\n3. Insight Card Design:\n```typescript\ninterface InsightCard {\n  icon: string;           // Based on insightType\n  title: string;          // From insight.title\n  description: string;    // Truncated insight.description\n  priority: 'high' | 'medium' | 'low'; // Color coding\n  correlation?: number;   // Show badge if correlation insight\n  timestamp: Date;        // When generated\n}\n```\n\n4. Detailed Insight View (`app/insights/[id].tsx`):\n   - Full description text\n   - Recommendation with call-to-action\n   - Supporting chart/data if applicable\n   - 'Was this helpful?' feedback buttons\n   - Share insight button (future)\n\n5. Create API client in `lib/api/insights.ts`:\n```typescript\nexport const insightsApi = {\n  getAll: () => apiClient.get('/api/insights'),\n  getById: (id: string) => apiClient.get(`/api/insights/${id}`),\n  markViewed: (id: string) => apiClient.put(`/api/insights/${id}/viewed`),\n  dismiss: (id: string) => apiClient.put(`/api/insights/${id}/dismissed`),\n  submitFeedback: (id: string, helpful: boolean) =>\n    apiClient.put(`/api/insights/${id}/feedback`, { helpful }),\n}\n```\n\n6. Add insights badge to tab bar showing unread count",
        "testStrategy": "1. Component tests for insight cards\n2. Test swipe-to-dismiss interaction\n3. Test feedback submission flow\n4. Test empty and loading states\n5. Test priority-based sorting\n6. Visual regression tests for card styles",
        "priority": "medium",
        "dependencies": [
          "8"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Implement AR Portion Size Measurement",
        "description": "Add AR capability to measure food portion dimensions and improve nutrition estimation accuracy.",
        "details": "1. Install AR dependencies:\n   - expo-three (already installed - three.js is in dependencies)\n   - expo-gl (already installed)\n   - @react-three/fiber for React Native\n\n2. Create AR measurement component in `lib/components/ARPortionMeasure.tsx`:\n   - Initialize AR session with plane detection\n   - Render measurement guides on detected surfaces\n   - Allow user to place measurement points\n   - Calculate bounding box dimensions (width, height, depth)\n   - Return dimensions in centimeters\n\n3. Update food scanning flow (`app/scan-food.tsx`):\n   - Add 'Measure with AR' button after capturing photo\n   - Launch AR measurement overlay\n   - Pass dimensions to food analysis API\n   - Update `mockMeasurements` with real AR data\n\n4. AR measurement flow:\n   1. User captures food photo\n   2. User taps 'Measure Portion'\n   3. AR view opens with plane detection\n   4. User taps to place corner points (4 points for bounding box)\n   5. App calculates volume and converts to portion weight\n   6. Dimensions sent to /api/food/analyze\n\n5. Dimension to weight conversion (in food_analysis_service.py):\n   - Already implemented in `_estimate_portion_from_dimensions()`\n   - Uses food density estimates\n   - Returns estimated weight in grams\n\n6. Calibration feature:\n   - Include reference object option (credit card, hand)\n   - Use known dimensions to calibrate scale\n   - Improve accuracy for subsequent measurements\n\n7. Fallback handling:\n   - If AR not supported (older devices), show manual size picker\n   - Options: Small, Medium, Large with example photos",
        "testStrategy": "1. Unit tests for dimension calculation\n2. Test AR component mounting/unmounting\n3. Test plane detection callbacks\n4. Integration test with mock AR data\n5. Test fallback to manual size picker\n6. Manual testing on physical device with AR support\n7. Test calibration accuracy with known objects",
        "priority": "low",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Install AR Dependencies and Configure Native Modules",
            "description": "Add required AR dependencies for React Native/Expo including @react-three/fiber, react-three-fiber, and configure native AR capabilities for iOS (ARKit) and Android (ARCore).",
            "dependencies": [],
            "details": "1. Install @react-three/fiber and react-three-fiber packages\n2. Configure expo plugins for AR in app.json (expo-camera already configured)\n3. Set up iOS ARKit permissions in Info.plist (NSCameraUsageDescription already exists)\n4. Configure Android ARCore requirements in AndroidManifest.xml\n5. Verify expo-gl and three.js integration\n6. Create basic AR session test to verify setup\n7. Document AR capability requirements for devices (iOS 11+, ARCore-compatible Android)",
            "status": "done",
            "testStrategy": "1. Test package installation with npm/yarn\n2. Verify expo-gl renders basic 3D scene\n3. Test AR session initialization on iOS simulator (limited) and physical device\n4. Verify ARKit permissions prompt\n5. Test Android ARCore availability detection",
            "parentId": "undefined",
            "updatedAt": "2025-12-05T19:10:26.758Z"
          },
          {
            "id": 2,
            "title": "Create Interactive AR Measurement Component",
            "description": "Build the core ARPortionMeasure component that allows users to tap 4 corner points to create a bounding box and measure food portion dimensions in real-world coordinates.",
            "dependencies": [
              1
            ],
            "details": "1. Create lib/components/ARPortionMeasure.tsx component\n2. Initialize AR session with plane detection enabled\n3. Implement tap-to-place point placement (4 corners for bounding box)\n4. Convert screen coordinates to world coordinates using AR raycasting\n5. Calculate real-world dimensions (width, height, depth) from placed points\n6. Display visual guides showing detected plane surface\n7. Render bounding box overlay with dimension labels\n8. Add point placement indicators and connection lines\n9. Implement reset/undo functionality for point placement\n10. Return ARMeasurement type with confidence scoring based on plane detection quality\n11. Handle edge cases: insufficient plane detection, invalid point placement",
            "status": "done",
            "testStrategy": "1. Unit tests for coordinate conversion calculations\n2. Component tests for point placement state management\n3. Test bounding box dimension calculations with known distances\n4. Test plane detection callbacks and state updates\n5. Integration test with mock AR session data\n6. Manual testing on physical device with various surfaces\n7. Test reset/undo functionality",
            "parentId": "undefined",
            "updatedAt": "2025-12-05T19:16:24.790Z"
          },
          {
            "id": 3,
            "title": "Build AR Measurement Modal/Overlay Screen",
            "description": "Create the modal screen (app/ar-measure-portion.tsx) that launches the AR measurement experience with user instructions and controls.",
            "dependencies": [
              2
            ],
            "details": "1. Create app/ar-measure-portion.tsx as a modal screen\n2. Integrate ARPortionMeasure component into modal\n3. Design instruction UI:\n   - Step-by-step guide for users (detect plane, place 4 corners)\n   - Visual indicators for current step\n   - Progress indicator during plane detection\n4. Add control buttons:\n   - Confirm measurement (validates 4 points placed)\n   - Cancel and return to scan screen\n   - Reset measurement (clear all points)\n5. Display real-time measurement quality indicator\n6. Show current dimensions as user places points\n7. Handle AR session lifecycle (start on mount, cleanup on unmount)\n8. Add error states: no plane detected, AR not supported\n9. Implement navigation: return measured dimensions to caller",
            "status": "done",
            "testStrategy": "1. Component mounting/unmounting tests\n2. Test navigation with expo-router params\n3. Test confirm button validation (requires 4 points)\n4. Test cancel navigation back to scan screen\n5. Test reset functionality clears all state\n6. Integration test: full flow from scan to measurement to confirmation",
            "parentId": "undefined",
            "updatedAt": "2025-12-05T19:22:51.508Z"
          },
          {
            "id": 4,
            "title": "Integrate AR Measurement into Food Scanning Flow",
            "description": "Update scan-food.tsx to include 'Measure with AR' button after photo capture, launch the AR measurement modal, and pass captured dimensions to the food analysis API.",
            "dependencies": [
              3
            ],
            "details": "1. Update scan-food.tsx after photo capture (line 114 area)\n2. Add 'Measure with AR' button alongside 'Analyze Food' button\n3. Implement AR measurement flow:\n   - Launch ar-measure-portion modal\n   - Receive ARMeasurement result from modal\n   - Store measurements in component state\n4. Update foodAnalysisApi.analyzeFood() call to include measurements\n5. Replace mockMeasurements with real AR data\n6. Display measurement quality indicator in UI (high/medium/low badge)\n7. Show captured dimensions in preview (width x height x depth)\n8. Allow re-measurement before final analysis\n9. Handle AR not available gracefully (hide button, show alternative)\n10. Update UI flow: Photo → Measure (optional) → Analyze → Results",
            "status": "done",
            "testStrategy": "1. Test button visibility after photo capture\n2. Test modal launch with expo-router\n3. Test receiving ARMeasurement data from modal\n4. Test API call includes measurements in request\n5. Test UI updates with measurement quality indicator\n6. Integration test: full scan flow with AR measurement\n7. Test fallback when AR not available",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Reference Object Calibration Feature",
            "description": "Build calibration wizard allowing users to use a credit card or other reference object to improve AR measurement accuracy.",
            "dependencies": [
              2
            ],
            "details": "1. Create lib/components/ARCalibration.tsx component\n2. Implement credit card calibration mode:\n   - Standard dimensions: 85.60mm × 53.98mm\n   - AR measurement of credit card\n   - Calculate calibration factor: measured/actual\n3. Build calibration wizard UI:\n   - Introduction screen explaining calibration\n   - Place credit card on surface instructions\n   - Measure card with AR (4 corner points)\n   - Validation: check if dimensions are reasonable (within 20% of standard)\n   - Success/failure feedback\n4. Store calibration factor in AsyncStorage/SecureStore\n5. Apply calibration to subsequent measurements (multiply by factor)\n6. Add calibration status indicator in AR measurement screen\n7. Optional: Allow re-calibration from settings\n8. Optional: Support other reference objects (smartphone, hand span)\n9. Create lib/utils/calibration.ts for storage and retrieval",
            "status": "done",
            "testStrategy": "1. Test calibration factor calculation\n2. Test storage and retrieval of calibration data\n3. Test validation of measured card dimensions\n4. Test applying calibration to measurements\n5. Component tests for calibration wizard\n6. Integration test: calibrate then measure food\n7. Test calibration persistence across app restarts",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Create Fallback Manual Size Picker for Non-AR Devices",
            "description": "Build a manual size selection UI for devices without AR/LiDAR support, providing Small/Medium/Large presets with visual references.",
            "dependencies": [],
            "details": "1. Create lib/components/ManualSizePicker.tsx component\n2. Implement size selector options:\n   - Small (e.g., 5cm × 5cm × 5cm → ~87g assuming 0.7 density)\n   - Medium (e.g., 10cm × 10cm × 10cm → ~700g)\n   - Large (e.g., 15cm × 15cm × 15cm → ~2.3kg)\n   - Custom (slider input for each dimension)\n3. Add visual reference images for each size:\n   - Small: Size of a golf ball\n   - Medium: Size of a baseball\n   - Large: Size of a grapefruit\n4. Implement custom slider:\n   - Width slider (1-30cm)\n   - Height slider (1-30cm)\n   - Depth slider (1-30cm)\n   - Real-time volume calculation display\n5. Convert selected size to ARMeasurement type:\n   - Set confidence: 'low' (manual estimate)\n   - Set planeDetected: false\n   - Set distance, width, height, depth\n6. Integrate into scan-food.tsx as fallback when AR unavailable\n7. Show manual picker when device lacks AR support or user declines AR permissions",
            "status": "done",
            "testStrategy": "1. Component tests for size selection state\n2. Test dimension calculations for presets\n3. Test slider value updates and bounds\n4. Test conversion to ARMeasurement format\n5. Test integration with scan flow\n6. Visual regression tests for UI\n7. Test device AR capability detection",
            "parentId": "undefined",
            "updatedAt": "2025-12-05T18:02:37.997Z"
          },
          {
            "id": 7,
            "title": "Add Dimension-to-Weight Conversion Utilities",
            "description": "Create client-side utilities for volume calculation, food density lookup, and weight estimation to complement the ML service's backend estimation.",
            "dependencies": [],
            "details": "1. Create lib/utils/portion-estimation.ts utility file\n2. Implement volume calculation:\n   - volumeFromDimensions(width, height, depth): cm³\n   - applyShapeFactor(volume, shapeFactor): adjusted cm³\n3. Create food density lookup table:\n   - Common foods with g/cm³ density values\n   - Categorized by food type (fruits, vegetables, proteins, grains)\n   - Default density for unknown foods\n4. Implement weight estimation:\n   - estimateWeight(volume, foodType): grams\n   - Confidence score based on food type match\n   - Apply min/max bounds (1g - 5000g)\n5. Add unit conversion helpers:\n   - cmToInches(cm), inchesToCm(inches)\n   - gramsToOz(grams), ozToGrams(oz)\n   - volumeCm3ToMl(cm3), mlToVolumeCm3(ml)\n6. Create TypeScript interfaces for density data\n7. Export utility functions for use in components",
            "status": "done",
            "testStrategy": "1. Unit tests for volume calculations with known dimensions\n2. Test shape factor application\n3. Test density lookup for various food types\n4. Test weight estimation accuracy\n5. Test unit conversions (bidirectional)\n6. Test bounds enforcement (min/max weight)\n7. Test confidence scoring logic",
            "updatedAt": "2025-12-05T17:51:26.304Z",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Write Comprehensive Tests for AR Measurement System",
            "description": "Create unit, component, and integration tests covering the entire AR measurement feature including edge cases and device compatibility.",
            "dependencies": [
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "1. Unit tests for dimension calculations:\n   - Test bounding box calculation from 4 points\n   - Test coordinate conversion (screen to world)\n   - Test volume and weight calculations\n   - Test calibration factor application\n2. Component tests for ARPortionMeasure:\n   - Test point placement state management\n   - Test plane detection callbacks\n   - Test measurement completion validation\n   - Test reset functionality\n3. Component tests for ar-measure-portion modal:\n   - Test modal lifecycle (mount, unmount)\n   - Test navigation with params\n   - Test instruction UI state transitions\n4. Integration tests for measurement flow:\n   - Test full flow: scan → measure → analyze\n   - Test with calibration applied\n   - Test fallback to manual picker\n   - Test error handling (no plane, invalid points)\n5. Mock tests for devices without AR:\n   - Mock AR availability check\n   - Test manual picker display\n   - Test manual measurements passed to API\n6. Test calibration accuracy:\n   - Test with known reference object dimensions\n   - Test calibration persistence\n   - Test validation logic\n7. Add test fixtures:\n   - Mock ARMeasurement data\n   - Mock AR session responses\n   - Mock plane detection results\n8. Create test documentation in README or docs/testing.md",
            "status": "done",
            "testStrategy": "1. Run full test suite with jest\n2. Verify 80%+ code coverage for AR modules\n3. Test on iOS simulator (limited AR)\n4. Test on physical iOS device with ARKit\n5. Test on Android device with ARCore\n6. Test on older devices without AR support\n7. Regression testing after changes",
            "parentId": "undefined",
            "updatedAt": "2025-12-05T19:45:52.543Z"
          }
        ],
        "updatedAt": "2025-12-05T19:45:57.388Z"
      },
      {
        "id": 11,
        "title": "Generate OpenAPI Documentation and Polish Production Readiness",
        "description": "Add comprehensive API documentation, perform security audit, and optimize performance for production deployment.",
        "details": "1. Generate OpenAPI/Swagger documentation:\n   - Backend (Express): Add swagger-jsdoc and swagger-ui-express\n   - ML Service (FastAPI): Already has built-in docs at /docs\n   - Document all endpoints with request/response schemas\n   - Add authentication requirements\n   - Include example requests and responses\n\n2. Express API documentation setup:\n```javascript\nimport swaggerJsdoc from 'swagger-jsdoc';\nimport swaggerUi from 'swagger-ui-express';\n\nconst options = {\n  definition: {\n    openapi: '3.0.0',\n    info: { title: 'Nutri API', version: '1.0.0' },\n    servers: [{ url: '/api' }],\n    components: {\n      securitySchemes: {\n        bearerAuth: { type: 'http', scheme: 'bearer' }\n      }\n    }\n  },\n  apis: ['./src/routes/*.ts'],\n};\n\napp.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerJsdoc(options)));\n```\n\n3. Performance optimization:\n   - Add database query logging to identify slow queries\n   - Implement connection pooling for PostgreSQL\n   - Add Redis caching for frequently accessed data (user profile, daily summary)\n   - Compress API responses with compression middleware\n   - Optimize Prisma queries with select/include\n\n4. Security audit checklist:\n   - Review all authentication flows\n   - Verify rate limiting is effective\n   - Check for SQL injection (Prisma handles this)\n   - Verify XSS prevention in sanitize middleware\n   - Review CORS configuration\n   - Ensure sensitive data not logged\n   - Check JWT secret rotation capability\n\n5. Production configuration:\n   - Environment variable validation on startup\n   - Health check endpoints for load balancers\n   - Graceful shutdown handling\n   - Error tracking integration (Sentry ready)\n   - Logging configuration (structured JSON logs)\n\n6. Mobile app optimization:\n   - Review bundle size\n   - Implement proper loading states\n   - Add offline detection and handling\n   - Optimize image handling\n\n7. Create deployment documentation:\n   - Docker setup for backend and ML service\n   - Environment variables reference\n   - Database migration guide\n   - Monitoring recommendations",
        "testStrategy": "1. Validate OpenAPI spec with swagger-cli validate\n2. Load testing with k6 or artillery (100 concurrent users)\n3. Security scan with npm audit and OWASP ZAP\n4. Test rate limiting triggers correctly\n5. Test graceful shutdown\n6. Verify logging output format\n7. Test health check endpoints\n8. Performance benchmark for critical endpoints",
        "priority": "low",
        "dependencies": [
          "2",
          "3",
          "4",
          "6"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Implement Responsive UI Design for iPhone and iPad Devices",
        "description": "Comprehensive responsive design implementation covering all iPhone sizes (2020+) and iPads with both screen orientations. Lock iPhones to portrait mode while supporting iPad landscape/portrait. Test and optimize all 17 app screens across device categories.",
        "details": "## Technical Implementation Details\n\n### Breakpoint System (in logical pixels)\n```typescript\nconst breakpoints = {\n  // iPhones\n  iPhoneSE: { width: 375, height: 667 },      // iPhone SE 3rd gen\n  iPhoneMini: { width: 375, height: 812 },    // iPhone 12/13 Mini\n  iPhoneMedium: { width: 390, height: 844 },  // iPhone 12/13/14\n  iPhonePro: { width: 393, height: 852 },     // iPhone 14/15/16 Pro\n  iPhoneMax: { width: 430, height: 932 },     // iPhone Pro Max/Plus\n  \n  // iPads\n  iPadMini: { width: 744, height: 1133 },     // iPad Mini\n  iPad: { width: 820, height: 1180 },         // iPad/iPad Air 11\"\n  iPadPro11: { width: 834, height: 1194 },    // iPad Pro 11\"\n  iPadAir13: { width: 1032, height: 1376 },   // iPad Air 13\"\n  iPadPro13: { width: 1024, height: 1366 },   // iPad Pro 13\"\n};\n\nconst deviceCategories = {\n  small: ['iPhoneSE', 'iPhoneMini'],\n  medium: ['iPhoneMedium', 'iPhonePro'],\n  large: ['iPhoneMax'],\n  tablet: ['iPadMini', 'iPad', 'iPadPro11', 'iPadAir13', 'iPadPro13'],\n};\n```\n\n### Responsive Hook Example\n```typescript\n// lib/hooks/useResponsive.ts\nimport { useWindowDimensions, Platform } from 'react-native';\n\nexport function useResponsive() {\n  const { width, height } = useWindowDimensions();\n  \n  const isTablet = width >= 744;\n  const isLandscape = width > height;\n  const deviceCategory = getDeviceCategory(width);\n  \n  const scale = (size: number) => {\n    const baseWidth = 390; // iPhone 14 as baseline\n    return (width / baseWidth) * size;\n  };\n  \n  return { width, height, isTablet, isLandscape, deviceCategory, scale };\n}\n```\n\n### Orientation Lock (app.json)\n```json\n{\n  \"expo\": {\n    \"orientation\": \"portrait\",\n    \"ios\": {\n      \"supportsTablet\": true,\n      \"requireFullScreen\": false,\n      \"userInterfaceStyle\": \"automatic\"\n    }\n  }\n}\n```\n\n### iPad-specific orientation unlock (runtime)\n```typescript\n// In root _layout.tsx\nimport * as ScreenOrientation from 'expo-screen-orientation';\n\nuseEffect(() => {\n  async function configureOrientation() {\n    if (Platform.OS === 'ios' && Platform.isPad) {\n      await ScreenOrientation.unlockAsync();\n    } else {\n      await ScreenOrientation.lockAsync(\n        ScreenOrientation.OrientationLock.PORTRAIT_UP\n      );\n    }\n  }\n  configureOrientation();\n}, []);\n```\n\n### Simulator Testing Checklist\nEach screen must be tested on these simulators:\n- [ ] iPhone SE (3rd generation) - iOS 17+\n- [ ] iPhone 13 Mini - iOS 17+\n- [ ] iPhone 14 - iOS 17+\n- [ ] iPhone 15 Pro - iOS 17+\n- [ ] iPhone 15 Pro Max - iOS 17+\n- [ ] iPad Mini (6th generation) - Portrait\n- [ ] iPad Mini (6th generation) - Landscape\n- [ ] iPad Pro 11-inch - Portrait\n- [ ] iPad Pro 11-inch - Landscape\n- [ ] iPad Pro 13-inch - Portrait\n- [ ] iPad Pro 13-inch - Landscape\n\n### Safe Area Considerations\n- Use SafeAreaView consistently\n- Handle Dynamic Island on iPhone 14 Pro+\n- Handle home indicator on all Face ID devices\n- Handle notch on older Face ID devices\n- Handle status bar on iPhone SE\n\n### Testing Commands\n```bash\n# List available simulators\nxcrun simctl list devices available\n\n# Boot specific simulator\nxcrun simctl boot \"iPhone SE (3rd generation)\"\nxcrun simctl boot \"iPhone 15 Pro Max\"\nxcrun simctl boot \"iPad Pro 13-inch (M4)\"\n\n# Run app on specific simulator\nnpx expo run:ios --device \"iPhone SE (3rd generation)\"\nnpx expo run:ios --device \"iPad Pro 13-inch (M4)\"\n```",
        "testStrategy": "## Testing Strategy\n\n### Unit Tests\n- Test useResponsive hook returns correct device categories\n- Test scale functions produce expected values\n- Test breakpoint detection logic\n\n### Visual Regression Testing\n- Screenshot each screen on each device category\n- Compare layouts visually\n- Verify no text truncation or overflow\n- Verify touch targets are accessible (44pt minimum)\n\n### Manual Testing Checklist per Screen\n\n#### For each of the 17 screens, verify:\n1. **Layout Integrity**\n   - No horizontal scrolling when not intended\n   - Content fits within safe areas\n   - Proper padding/margins on all edges\n\n2. **Typography**\n   - All text is readable\n   - No text truncation (unless intentional with ellipsis)\n   - Font sizes appropriate for device\n\n3. **Interactive Elements**\n   - Buttons are tappable (44pt minimum)\n   - Form fields are usable\n   - Scrolling works smoothly\n\n4. **Orientation (iPad only)**\n   - Smooth rotation transition\n   - Layout adapts correctly\n   - No content loss during rotation\n\n### Device Matrix\n| Screen | SE | Mini | Medium | Pro Max | iPad Mini P | iPad Mini L | iPad Pro P | iPad Pro L |\n|--------|:--:|:----:|:------:|:-------:|:-----------:|:-----------:|:----------:|:----------:|\n| welcome | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| signin | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| signup | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| forgot-password | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| reset-password | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| home (tabs/index) | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| profile | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| health | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| add-meal | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| scan-food | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| ar-scan-food | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| ar-measure | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| health-settings | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| health/[metricType] | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| health/add | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| not-found | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n| layouts | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ | ☐ |\n\n### Acceptance Criteria\n- All screens render correctly on all device categories\n- No visual bugs, overflow, or truncation\n- Forms are usable on all devices\n- iPad supports both orientations seamlessly\n- Performance remains smooth on older devices (iPhone SE)\n- Safe areas properly respected on all devices",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Responsive Design Utility Library",
            "description": "Build the foundational responsive design utilities including breakpoint definitions, device category constants, and helper functions for device detection. Create lib/responsive/breakpoints.ts with all iPhone (2020+) and iPad screen dimensions.",
            "details": "Create the following files:\n- lib/responsive/breakpoints.ts - Device breakpoint constants\n- lib/responsive/types.ts - TypeScript types for device categories\n- lib/responsive/helpers.ts - Utility functions for device detection\n\nBreakpoints to define:\n- iPhoneSE: 375x667 pts\n- iPhoneMini: 375x812 pts  \n- iPhoneMedium: 390x844 pts\n- iPhonePro: 393x852 pts\n- iPhoneMax: 430x932 pts\n- iPadMini: 744x1133 pts\n- iPad: 820x1180 pts\n- iPadPro11: 834x1194 pts\n- iPadAir13: 1032x1376 pts\n- iPadPro13: 1024x1366 pts",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12,
            "updatedAt": "2025-12-10T16:49:10.825Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configure Orientation Lock for iPhone/iPad",
            "description": "Set up orientation locking - portrait-only for iPhones, both orientations for iPads. Update app.json and implement runtime orientation control using expo-screen-orientation.",
            "details": "1. Update app.json with orientation: \"portrait\" and ios.supportsTablet: true\n2. Install expo-screen-orientation if not present\n3. Implement runtime detection in _layout.tsx:\n   - Lock to PORTRAIT_UP for iPhone\n   - Unlock for iPad (Platform.isPad)\n4. Test orientation behavior on both device types",
            "status": "done",
            "dependencies": [
              "12.1"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-10T16:51:33.416Z"
          },
          {
            "id": 3,
            "title": "Implement useResponsive Hook",
            "description": "Create a comprehensive useResponsive hook that provides device category detection, scaling functions, and responsive utilities. This hook will be the primary interface for responsive design throughout the app.",
            "details": "Create lib/hooks/useResponsive.ts with:\n- useWindowDimensions integration\n- Device category detection (small/medium/large/tablet)\n- isTablet boolean\n- isLandscape boolean  \n- scale() function for proportional sizing\n- scaleFont() for typography\n- getSpacing() for responsive margins/padding\n- Platform-aware logic for iOS/Android differences\n\nExport types and hook from lib/hooks/index.ts",
            "status": "done",
            "dependencies": [
              "12.1"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-10T16:53:13.680Z"
          },
          {
            "id": 4,
            "title": "Create Responsive Typography and Spacing System",
            "description": "Build a responsive typography scale and spacing system that adapts to different device sizes. Create design tokens for font sizes, line heights, and spacing values.",
            "details": "Create lib/responsive/typography.ts:\n- Base font sizes for each device category\n- Responsive font scale (xs, sm, base, lg, xl, 2xl, 3xl)\n- Line height multipliers\n- Letter spacing values\n\nCreate lib/responsive/spacing.ts:\n- Spacing scale (xs: 4, sm: 8, md: 16, lg: 24, xl: 32, 2xl: 48)\n- Responsive padding/margin helpers\n- Safe area aware spacing\n\nEnsure minimum touch targets of 44pt on all devices",
            "status": "done",
            "dependencies": [
              "12.3"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-10T16:55:46.367Z"
          },
          {
            "id": 5,
            "title": "Build Responsive Component Primitives",
            "description": "Create reusable responsive component wrappers that handle common responsive patterns - containers, cards, grids, and form layouts that adapt to device size.",
            "details": "Create components in lib/components/responsive/:\n- ResponsiveContainer.tsx - Max-width container with padding\n- ResponsiveGrid.tsx - Adaptive grid (1-col phone, 2-col tablet)\n- ResponsiveCard.tsx - Card with adaptive sizing\n- ResponsiveForm.tsx - Form layout wrapper\n- ResponsiveText.tsx - Text with automatic font scaling\n\nEach component should:\n- Use useResponsive hook\n- Support iPad landscape/portrait layouts\n- Handle safe areas properly\n- Be fully typed with TypeScript",
            "status": "done",
            "dependencies": [
              "12.3",
              "12.4"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-10T16:58:06.022Z"
          },
          {
            "id": 6,
            "title": "Update Auth Screens for Responsive Design",
            "description": "Adapt all 5 authentication screens (welcome, signin, signup, forgot-password, reset-password) to be responsive across all device categories.",
            "details": "Update these screens:\n- app/auth/welcome.tsx\n- app/auth/signin.tsx\n- app/auth/signup.tsx\n- app/auth/forgot-password.tsx\n- app/auth/reset-password.tsx\n\nFor each screen:\n1. Import and use useResponsive hook\n2. Replace hardcoded dimensions with responsive values\n3. Ensure forms have appropriate widths on tablets (max-width)\n4. Adjust padding and margins for each device category\n5. Verify text is readable on all sizes\n6. Center content appropriately on larger screens\n7. Handle keyboard avoiding behavior on all sizes",
            "status": "done",
            "dependencies": [
              "12.5"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-10T18:18:05.270Z"
          },
          {
            "id": 7,
            "title": "Update Main Tab Screens for Responsive Design",
            "description": "Adapt the 3 main tab screens (home/index, profile, health) and tab layout to be responsive across all device categories.",
            "details": "Update these screens:\n- app/(tabs)/index.tsx - Home dashboard\n- app/(tabs)/profile.tsx - User profile\n- app/(tabs)/health.tsx - Health overview\n- app/(tabs)/_layout.tsx - Tab navigation\n\nFocus areas:\n1. Dashboard cards should use grid on tablets\n2. Profile layout may use side-by-side on landscape iPad\n3. Health metrics should display in responsive grid\n4. Tab bar should adapt sizing for tablets\n5. Charts and graphs must scale appropriately\n6. Lists should have appropriate row heights per device",
            "status": "done",
            "dependencies": [
              "12.5"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-10T19:07:23.738Z"
          },
          {
            "id": 8,
            "title": "Update Meal and Scanning Screens for Responsive Design",
            "description": "Adapt the 4 meal/scanning screens (add-meal, scan-food, ar-scan-food, ar-measure) to be responsive, with special attention to camera and AR views.",
            "details": "Update these screens:\n- app/add-meal.tsx - Manual meal entry form\n- app/scan-food.tsx - Camera food scanning\n- app/ar-scan-food.tsx - AR food recognition\n- app/ar-measure.tsx - AR portion measurement\n\nSpecial considerations:\n1. Camera views must fill appropriate area on all devices\n2. AR overlays need to scale with screen size\n3. Form inputs in add-meal need responsive widths\n4. Scanning UI controls must have 44pt+ touch targets\n5. Results display should use available space on tablets\n6. Modal presentations should be appropriately sized",
            "status": "done",
            "dependencies": [
              "12.5"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-11T17:01:14.494Z"
          },
          {
            "id": 9,
            "title": "Update Health Screens for Responsive Design",
            "description": "Adapt the 3 health-related screens (health-settings, health/[metricType], health/add) and error screen (+not-found) to be responsive.",
            "details": "Update these screens:\n- app/health-settings.tsx - Health settings\n- app/health/[metricType].tsx - Metric detail view\n- app/health/add.tsx - Add health metric\n- app/+not-found.tsx - 404 error page\n- app/_layout.tsx - Root layout\n\nFocus areas:\n1. Settings lists should have appropriate row heights\n2. Metric charts must scale for different screen sizes\n3. Add metric form should be responsive\n4. Error page should center content on all devices\n5. Root layout should handle safe areas consistently",
            "status": "done",
            "dependencies": [
              "12.5"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-11T17:06:57.390Z"
          },
          {
            "id": 10,
            "title": "iPhone Simulator Testing - All Categories",
            "description": "Run comprehensive simulator testing on all iPhone device categories (SE, Mini, Medium, Pro Max) verifying all 17 screens render correctly in portrait mode.",
            "details": "Test on these simulators:\n1. iPhone SE (3rd generation) - Small/Legacy (375x667)\n2. iPhone 13 Mini - Mini category (375x812)\n3. iPhone 14 - Medium category (390x844)\n4. iPhone 15 Pro - Pro category (393x852)\n5. iPhone 15 Pro Max - Max category (430x932)\n\nFor each device, verify ALL 17 screens:\n- Auth: welcome, signin, signup, forgot-password, reset-password\n- Tabs: home, profile, health\n- Meals: add-meal, scan-food, ar-scan-food, ar-measure\n- Health: health-settings, [metricType], add\n- System: not-found, layouts\n\nChecklist per screen:\n☐ No horizontal overflow\n☐ Text readable, no truncation\n☐ Touch targets >= 44pt\n☐ Safe areas respected\n☐ Forms usable with keyboard",
            "status": "done",
            "dependencies": [
              "12.6",
              "12.7",
              "12.8",
              "12.9"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-11T17:15:01.128Z"
          },
          {
            "id": 11,
            "title": "iPad Simulator Testing - Both Orientations",
            "description": "Run comprehensive simulator testing on iPad devices (Mini, Air, Pro) in both portrait and landscape orientations, verifying all 17 screens adapt correctly.",
            "details": "Test on these simulators:\n1. iPad Mini (6th generation) - Portrait & Landscape\n2. iPad Air 11-inch - Portrait & Landscape\n3. iPad Pro 11-inch - Portrait & Landscape\n4. iPad Pro 13-inch - Portrait & Landscape\n\nFor each device AND orientation, verify ALL 17 screens:\n- Auth: welcome, signin, signup, forgot-password, reset-password\n- Tabs: home, profile, health\n- Meals: add-meal, scan-food, ar-scan-food, ar-measure\n- Health: health-settings, [metricType], add\n- System: not-found, layouts\n\nChecklist per screen:\n☐ Layout adapts to orientation change\n☐ No content loss on rotation\n☐ Grids display correctly (multi-column where appropriate)\n☐ Forms centered with max-width\n☐ Charts scale appropriately\n☐ Touch targets >= 44pt\n☐ Smooth rotation animation",
            "status": "done",
            "dependencies": [
              "12.6",
              "12.7",
              "12.8",
              "12.9"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-11T17:16:45.237Z"
          },
          {
            "id": 12,
            "title": "Create Testing Documentation and Verification Report",
            "description": "Document all responsive design testing results, create a verification matrix with screenshots, and compile final report of any issues found and resolutions.",
            "details": "Create documentation in docs/responsive-design/:\n1. TESTING-MATRIX.md - Device x Screen verification grid\n2. BREAKPOINTS.md - Documentation of breakpoint system\n3. SCREENSHOTS/ - Folder with screenshots from each device\n4. ISSUES.md - Log of issues found and how resolved\n5. USAGE-GUIDE.md - How to use responsive utilities\n\nFinal verification matrix should show:\n| Screen | SE | Mini | Med | Max | iPad-P | iPad-L |\nWith ✓/✗ for each combination\n\nInclude simulator commands for future testing:\n- How to boot each simulator\n- How to run app on each device\n- How to take screenshots",
            "status": "done",
            "dependencies": [
              "12.10",
              "12.11"
            ],
            "parentTaskId": 12,
            "parentId": "undefined",
            "updatedAt": "2025-12-11T17:18:50.485Z"
          }
        ],
        "updatedAt": "2025-12-11T17:18:50.485Z"
      },
      {
        "id": 13,
        "title": "Integrate USDA FoodData Central Database with Scalable Food Classification System",
        "description": "Integrate the USDA FoodData Central API to expand the food database from ~100 items to 500K+ foods, AND implement a scalable multi-tier food classification architecture. This addresses the critical question: yes, integrating USDA's 500K+ food database requires a fundamentally different classification approach than the current ~100-class model.",
        "details": "## Overview\nThe current food database in `ml-service/app/data/food_database.py` has approximately 100 items with a simple classifier (`FoodAnalysisService._classify_food`). Integrating USDA FoodData Central's 500K+ foods requires a **multi-tier classification architecture** because:\n\n1. **No ML model can reliably classify 500K+ food classes** - even state-of-the-art research focuses on 500-2000 classes\n2. **USDA uses 5 distinct data types** with different classification schemas (Foundation, SR Legacy, Survey/FNDDS, Branded, Experimental)\n3. **User search + AI-assisted refinement** is more practical than pure image classification\n\n## USDA FoodData Central API\n- **API Endpoint**: https://api.nal.usda.gov/fdc/v1/\n- **API Key**: Free, requires registration at https://fdc.nal.usda.gov/api-key-signup.html\n- **Rate Limits**: 1,000 requests/hour per IP (can request increase)\n- **Data Types**: \n  - Foundation Foods (unprocessed/lightly processed)\n  - SR Legacy (comprehensive, final release 2018)\n  - Survey/FNDDS (dietary studies 2021-2023)\n  - Branded (commercial products)\n  - Experimental (research data)\n\n## Multi-Tier Classification Architecture\n\n### Tier 1: Coarse-Grained Visual Classifier (ML Model)\n**Purpose**: Classify images into 20-50 high-level food categories\n**Implementation**: `ml-service/app/ml_models/food_classifier_v3.py`\n\n```python\nclass FoodCategory(str, Enum):\n    # 25-30 categories mapping to USDA food groups\n    FRUITS_FRESH = \"fruits_fresh\"\n    FRUITS_PROCESSED = \"fruits_processed\"\n    VEGETABLES_LEAFY = \"vegetables_leafy\"\n    VEGETABLES_ROOT = \"vegetables_root\"\n    VEGETABLES_OTHER = \"vegetables_other\"\n    MEAT_RED = \"meat_red\"\n    MEAT_POULTRY = \"meat_poultry\"\n    SEAFOOD_FISH = \"seafood_fish\"\n    SEAFOOD_SHELLFISH = \"seafood_shellfish\"\n    DAIRY_MILK = \"dairy_milk\"\n    DAIRY_CHEESE = \"dairy_cheese\"\n    DAIRY_YOGURT = \"dairy_yogurt\"\n    GRAINS_BREAD = \"grains_bread\"\n    GRAINS_PASTA = \"grains_pasta\"\n    GRAINS_RICE = \"grains_rice\"\n    GRAINS_CEREAL = \"grains_cereal\"\n    LEGUMES = \"legumes\"\n    NUTS_SEEDS = \"nuts_seeds\"\n    BEVERAGES_HOT = \"beverages_hot\"\n    BEVERAGES_COLD = \"beverages_cold\"\n    SNACKS_SWEET = \"snacks_sweet\"\n    SNACKS_SAVORY = \"snacks_savory\"\n    MIXED_DISHES = \"mixed_dishes\"\n    FAST_FOOD = \"fast_food\"\n    CONDIMENTS_SAUCES = \"condiments_sauces\"\n    # ... additional categories\n\n@dataclass\nclass CoarseClassification:\n    category: FoodCategory\n    confidence: float\n    subcategory_hints: List[str]  # \"appears sliced\", \"grilled texture\", etc.\n    color_profile: Dict[str, float]  # dominant colors for refinement\n    texture_features: Dict[str, float]  # smooth, grainy, fibrous, etc.\n```\n\n**Model Architecture**:\n- Base: EfficientNet-B4 or ConvNeXt-Base (pretrained on ImageNet)\n- Fine-tuned on Food-2K + custom dataset\n- Output: Top-3 categories with confidence scores\n- Inference time: <100ms on CPU, <20ms on GPU\n\n### Tier 2: Category-Specific Fine-Grained Classifier (Optional ML)\n**Purpose**: Refine within categories (e.g., \"apple\" vs \"pear\" within FRUITS_FRESH)\n**Implementation**: Specialized sub-models loaded on-demand\n\n```python\nclass FinegrainedClassifierRegistry:\n    \"\"\"Registry of category-specific classifiers\"\"\"\n    \n    CLASSIFIERS = {\n        FoodCategory.FRUITS_FRESH: \"models/fruits_classifier_v1.onnx\",\n        FoodCategory.MEAT_RED: \"models/red_meat_classifier_v1.onnx\",\n        FoodCategory.MIXED_DISHES: None,  # Too complex, skip to search\n        # ...\n    }\n    \n    async def classify_finegrained(\n        self, \n        image: Image.Image, \n        category: FoodCategory\n    ) -> Optional[List[FinegrainedPrediction]]:\n        \"\"\"Returns None if no specialized classifier available\"\"\"\n        model_path = self.CLASSIFIERS.get(category)\n        if not model_path:\n            return None\n        # Load and run category-specific model\n        ...\n```\n\n**Category Coverage**:\n- Fruits: ~200 classes (achievable with 85%+ accuracy)\n- Vegetables: ~150 classes\n- Meat/Poultry: ~100 classes\n- Seafood: ~150 classes\n- Branded/Processed: Skip (use text search)\n- Mixed dishes: Skip (use user input + search)\n\n### Tier 3: USDA Search Integration (Primary Lookup)\n**Purpose**: Map classifications to specific USDA FDC entries\n**Implementation**: `server/src/services/foodDatabaseService.ts`\n\n```typescript\ninterface USDASearchStrategy {\n  // Combine visual classification with text search\n  searchWithClassificationContext(\n    query: string,\n    classificationHints: ClassificationHints\n  ): Promise<USDASearchResult[]>;\n}\n\ninterface ClassificationHints {\n  coarseCategory: string;\n  finegrainedSuggestions?: string[];\n  colorProfile?: Record<string, number>;\n  cookingMethod?: string;\n  brandDetected?: string;  // OCR from packaging\n  portionEstimate?: number;  // grams from AR\n}\n\nconst searchWithContext = async (\n  userQuery: string,\n  hints: ClassificationHints\n): Promise<USDAFoodItem[]> => {\n  // 1. Build enhanced search query\n  const enhancedQuery = buildEnhancedQuery(userQuery, hints);\n  \n  // 2. Filter by USDA data types based on category\n  const dataTypes = getRelevantDataTypes(hints.coarseCategory);\n  // Foundation/SR Legacy for whole foods\n  // Branded for packaged foods\n  // Survey for mixed dishes\n  \n  // 3. Execute search with USDA API\n  const results = await usdaApi.search({\n    query: enhancedQuery,\n    dataType: dataTypes,\n    pageSize: 25,\n    sortBy: 'dataType.keyword',  // Prefer Foundation over Branded\n  });\n  \n  // 4. Re-rank results using classification hints\n  return rerankResults(results, hints);\n};\n```\n\n### Tier 4: User Confirmation + Learning Loop\n**Purpose**: Correct misclassifications and improve over time\n**Implementation**: Feedback-driven learning system\n\n```typescript\n// server/src/services/foodFeedbackService.ts\ninterface FoodFeedback {\n  originalPrediction: string;\n  userSelection: string;  // FDC ID selected\n  imageHash: string;      // For deduplication\n  classificationHints: ClassificationHints;\n  timestamp: Date;\n  userId: string;\n}\n\n// Aggregate feedback for model retraining triggers\nconst aggregateFeedback = async (): Promise<RetrainingSignal> => {\n  // When >100 corrections for a category, signal retraining\n  ...\n};\n```\n\n## Backend API Routes (Extended)\n\n### Food Search Endpoints\n```\nGET /api/foods/search?q={query}&limit={limit}&page={page}&dataType={type}\nGET /api/foods/:fdcId\nGET /api/foods/:fdcId/nutrients\nGET /api/foods/popular\nGET /api/foods/recent  (user's recent selections)\n```\n\n### Classification-Assisted Endpoints\n```\nPOST /api/foods/classify-and-search\n  Body: { image: base64, dimensions?: ARDimensions }\n  Response: {\n    classification: { category, confidence, suggestions },\n    searchResults: USDAFoodItem[],\n    portionEstimate?: number\n  }\n\nPOST /api/foods/feedback\n  Body: { classificationId, selectedFdcId, wasCorrect }\n```\n\n## Caching Strategy (Multi-Layer)\n\n### Layer 1: Edge Cache (CDN)\n- Popular food queries: 24-hour TTL\n- Static food data: 7-day TTL\n\n### Layer 2: Redis Cache\n```typescript\n// Search results: 1-hour TTL\nawait redis.setex(`search:${hash(query+dataTypes)}`, 3600, JSON.stringify(results));\n\n// Individual food data: 24-hour TTL\nawait redis.setex(`food:${fdcId}`, 86400, JSON.stringify(foodData));\n\n// User's recent foods: 30-day TTL\nawait redis.zadd(`user:${userId}:foods`, timestamp, fdcId);\n\n// Classification results: 1-hour TTL (for same image)\nawait redis.setex(`classify:${imageHash}`, 3600, JSON.stringify(classification));\n```\n\n### Layer 3: Local SQLite Cache (Mobile)\n```typescript\n// Cache top 10K most searched foods locally\n// Weekly sync for updates\n// Enables offline search with degraded ranking\n```\n\n## Nutrient Mapping (Extended)\n\nMap USDA nutrient IDs to our schema (expanded set):\n```typescript\nconst NUTRIENT_MAPPING = {\n  // Core macros\n  1003: 'protein',      // g\n  1004: 'fat',          // g\n  1005: 'carbs',        // g (by difference)\n  1008: 'calories',     // kcal\n  \n  // Fiber & sugars\n  1079: 'fiber',        // g\n  2000: 'sugars_total', // g\n  1235: 'sugars_added', // g\n  \n  // Fats breakdown\n  1258: 'saturated_fat',     // g\n  1292: 'monounsaturated_fat', // g\n  1293: 'polyunsaturated_fat', // g\n  1257: 'trans_fat',         // g\n  1253: 'cholesterol',       // mg\n  \n  // Minerals\n  1093: 'sodium',       // mg\n  1092: 'potassium',    // mg\n  1087: 'calcium',      // mg\n  1089: 'iron',         // mg\n  1090: 'magnesium',    // mg\n  \n  // Vitamins\n  1106: 'vitamin_a',    // mcg RAE\n  1162: 'vitamin_c',    // mg\n  1114: 'vitamin_d',    // mcg\n  \n  // Amino acids (for Lysine/Arginine tracking)\n  1213: 'lysine',       // g\n  1220: 'arginine',     // g\n};\n```\n\n## ML Model Training Pipeline\n\n### Phase 1: Coarse Classifier Training\n```python\n# ml-service/scripts/train_coarse_classifier.py\n\n# Dataset: Food-2K + custom images\n# Classes: 25-30 food categories\n# Architecture: EfficientNet-B4\n# Training: 50 epochs, cosine LR schedule\n# Target: >90% top-1 accuracy, >98% top-3 accuracy\n\nfrom torchvision.models import efficientnet_b4\nfrom torch.utils.data import DataLoader\n\ndef train_coarse_classifier():\n    model = efficientnet_b4(pretrained=True)\n    model.classifier[-1] = nn.Linear(1792, NUM_CATEGORIES)\n    \n    # Training config\n    optimizer = AdamW(model.parameters(), lr=1e-4)\n    scheduler = CosineAnnealingLR(optimizer, T_max=50)\n    \n    # Mixed precision training\n    scaler = GradScaler()\n    \n    for epoch in range(50):\n        train_epoch(model, train_loader, optimizer, scaler)\n        validate(model, val_loader)\n        scheduler.step()\n```\n\n### Phase 2: Fine-Grained Classifier Training (Per Category)\n```python\n# Only for categories with clear visual distinctions\n# Skip: mixed dishes, branded foods, beverages\n\nTRAINABLE_CATEGORIES = [\n    'fruits_fresh',    # ~200 classes\n    'vegetables',      # ~150 classes\n    'meat_raw',        # ~50 classes\n    'seafood',         # ~150 classes\n]\n\ndef train_finegrained_classifier(category: str):\n    # Filter USDA FDC images for category\n    # Use Foundation Foods data type for quality images\n    # Augmentation: color jitter, rotation, scale\n    # Model: ResNet-50 or ConvNeXt-Small\n    ...\n```\n\n### Phase 3: Continuous Learning Pipeline\n```python\n# Trigger retraining when:\n# 1. >100 corrections for a category\n# 2. Monthly scheduled retraining\n# 3. New USDA data release\n\n@celery.task\ndef check_retraining_triggers():\n    feedback_stats = aggregate_user_feedback()\n    for category, stats in feedback_stats.items():\n        if stats.correction_count > 100:\n            queue_retraining_job(category, stats.feedback_data)\n```\n\n## Environment Variables (Extended)\n```env\n# USDA API\nUSDA_API_KEY=your-api-key-here\nUSDA_API_BASE_URL=https://api.nal.usda.gov/fdc/v1\nUSDA_RATE_LIMIT_PER_HOUR=1000\n\n# ML Model Configuration\nML_MODEL_COARSE_PATH=models/food_coarse_v1.onnx\nML_MODEL_INFERENCE_DEVICE=cpu  # or cuda\nML_MODEL_CONFIDENCE_THRESHOLD=0.6\n\n# Caching\nREDIS_URL=redis://localhost:6379\nCACHE_SEARCH_TTL_SECONDS=3600\nCACHE_FOOD_TTL_SECONDS=86400\n\n# Feature Flags\nENABLE_FINEGRAINED_CLASSIFICATION=true\nENABLE_BRANDED_FOOD_SEARCH=true\nENABLE_FEEDBACK_COLLECTION=true\n```\n\n## Feasibility Analysis\n\n### What IS Feasible:\n1. ✅ Integrating USDA API for 500K+ food search\n2. ✅ Coarse classification into 25-50 categories (>90% accuracy achievable)\n3. ✅ Fine-grained classification for select categories (fruits, vegetables, meat)\n4. ✅ Hybrid search combining visual hints + text queries\n5. ✅ Progressive enhancement with user feedback\n\n### What is NOT Feasible:\n1. ❌ Direct 500K-class image classifier (no model can do this reliably)\n2. ❌ Accurate classification of branded/packaged foods (need barcode/OCR)\n3. ❌ Mixed dishes classification without user input\n4. ❌ Real-time model retraining (must be batch/scheduled)\n\n### Recommended Approach:\n**Hybrid Search-First Architecture**\n- Use ML for coarse categorization + portion estimation\n- Let user search/select from USDA results\n- Learn from corrections to improve suggestions\n- Barcode scanning for packaged foods (Phase 2)\n\n## Success Metrics (Extended)\n- Coarse classification: >90% top-1, >98% top-3 accuracy\n- Search returns results in <500ms (with caching)\n- 95%+ of common foods found in search\n- User selects from top-5 suggestions >80% of time\n- Nutrition data accuracy verified against USDA source\n- Model retraining pipeline completes in <4 hours",
        "testStrategy": "## Testing Strategy (Comprehensive)\n\n### Unit Tests\n\n#### ML Classification Tests\n```python\n# ml-service/tests/test_coarse_classifier.py\nclass TestCoarseClassifier:\n    def test_classification_output_shape(self):\n        \"\"\"Verify model outputs correct number of categories\"\"\"\n        \n    def test_confidence_scores_sum_to_one(self):\n        \"\"\"Softmax outputs should sum to ~1.0\"\"\"\n        \n    def test_inference_time_under_threshold(self):\n        \"\"\"Inference should complete in <100ms CPU\"\"\"\n        \n    def test_batch_inference(self):\n        \"\"\"Multiple images processed correctly\"\"\"\n        \n    def test_model_handles_various_image_sizes(self):\n        \"\"\"Resizing/preprocessing works for any input size\"\"\"\n        \n    def test_model_handles_grayscale_images(self):\n        \"\"\"Graceful handling of non-RGB input\"\"\"\n```\n\n#### USDA API Client Tests\n```typescript\n// server/src/__tests__/foodDatabaseService.test.ts\ndescribe('FoodDatabaseService', () => {\n  test('searchFoods returns properly typed results');\n  test('searchFoods handles empty query gracefully');\n  test('searchFoods respects dataType filter');\n  test('searchFoods paginates correctly');\n  test('getFoodById returns complete nutrition data');\n  test('getFoodById handles non-existent FDC ID');\n  test('nutrient mapping transforms USDA format to app schema');\n  test('nutrient mapping handles missing nutrients gracefully');\n  test('rate limit handling backs off appropriately');\n});\n```\n\n#### Caching Tests\n```typescript\ndescribe('FoodCacheService', () => {\n  test('cache hit returns data without API call');\n  test('cache miss fetches from API and caches');\n  test('cache expiration triggers fresh fetch');\n  test('cache handles Redis connection failure gracefully');\n  test('search result deduplication works correctly');\n});\n```\n\n### Integration Tests\n\n#### Classification Pipeline Tests\n```python\n# ml-service/tests/integration/test_classification_pipeline.py\nclass TestClassificationPipeline:\n    async def test_end_to_end_classification(self):\n        \"\"\"Image → Coarse → Fine-grained → Search suggestions\"\"\"\n        \n    async def test_classification_with_ar_dimensions(self):\n        \"\"\"Classification combined with portion estimation\"\"\"\n        \n    async def test_fallback_when_classifier_unavailable(self):\n        \"\"\"System degrades gracefully without ML model\"\"\"\n        \n    async def test_classification_caching(self):\n        \"\"\"Same image hash returns cached result\"\"\"\n```\n\n#### USDA API Integration Tests\n```typescript\n// Run with actual API (rate-limited test account)\ndescribe('USDA API Integration', () => {\n  test('search for \"apple\" returns Foundation Foods results');\n  test('search for \"coca cola\" returns Branded results');\n  test('getFoodById retrieves full nutrient profile');\n  test('API handles special characters in query');\n  test('API timeout is handled gracefully');\n  test('concurrent requests respect rate limits');\n});\n```\n\n#### Hybrid Search Tests\n```typescript\ndescribe('Hybrid Search', () => {\n  test('classification hints improve search ranking');\n  test('color profile helps distinguish similar foods');\n  test('cooking method hint filters appropriate results');\n  test('portion estimate affects serving size suggestions');\n});\n```\n\n### Mobile Tests\n\n#### Search UI Tests\n```typescript\n// __tests__/screens/FoodSearchScreen.test.tsx\ndescribe('FoodSearchScreen', () => {\n  test('renders search input and results list');\n  test('debounces search input (300ms)');\n  test('displays loading state during search');\n  test('displays error state on API failure');\n  test('displays empty state with suggestions');\n  test('tapping result opens food detail');\n  test('recent searches displayed on focus');\n  test('clear search button works');\n});\n```\n\n#### Classification Integration Tests\n```typescript\ndescribe('FoodClassificationScreen', () => {\n  test('camera capture triggers classification');\n  test('classification results displayed with confidence');\n  test('user can override classification');\n  test('AR dimensions captured when available');\n  test('portion estimate displayed');\n  test('proceed to search with classification hints');\n});\n```\n\n#### Offline Behavior Tests\n```typescript\ndescribe('Offline Mode', () => {\n  test('cached foods searchable offline');\n  test('recent selections available offline');\n  test('graceful degradation message shown');\n  test('classification works offline (model in app)');\n  test('sync queue for pending feedback');\n});\n```\n\n### Performance Tests\n\n#### Classification Performance\n```python\ndef test_coarse_classifier_latency():\n    \"\"\"Target: <100ms on CPU, <20ms on GPU\"\"\"\n    model = load_coarse_classifier()\n    images = load_test_images(100)\n    \n    start = time.time()\n    for img in images:\n        model.predict(img)\n    avg_latency = (time.time() - start) / 100\n    \n    assert avg_latency < 0.1  # 100ms\n\ndef test_finegrained_classifier_latency():\n    \"\"\"Target: <150ms on CPU\"\"\"\n    ...\n```\n\n#### Search Performance\n```typescript\ndescribe('Search Performance', () => {\n  test('cached search returns in <50ms');\n  test('uncached search returns in <500ms');\n  test('concurrent searches (10) complete in <2s');\n  test('large result sets (100 items) render in <100ms');\n});\n```\n\n#### Memory Tests\n```python\ndef test_model_memory_footprint():\n    \"\"\"Coarse model should use <500MB RAM\"\"\"\n    import tracemalloc\n    tracemalloc.start()\n    \n    model = load_coarse_classifier()\n    current, peak = tracemalloc.get_traced_memory()\n    \n    assert peak < 500 * 1024 * 1024  # 500MB\n```\n\n### Accuracy Tests\n\n#### Classification Accuracy\n```python\n# Run on held-out test set\ndef test_coarse_classifier_accuracy():\n    \"\"\"Target: >90% top-1, >98% top-3\"\"\"\n    model = load_coarse_classifier()\n    test_set = load_test_dataset()\n    \n    top1_correct = 0\n    top3_correct = 0\n    \n    for image, label in test_set:\n        predictions = model.predict_top_k(image, k=3)\n        if predictions[0].label == label:\n            top1_correct += 1\n        if label in [p.label for p in predictions]:\n            top3_correct += 1\n    \n    top1_acc = top1_correct / len(test_set)\n    top3_acc = top3_correct / len(test_set)\n    \n    assert top1_acc > 0.90\n    assert top3_acc > 0.98\n\ndef test_per_category_accuracy():\n    \"\"\"Ensure no category has <80% accuracy\"\"\"\n    ...\n```\n\n#### Nutrition Data Accuracy\n```typescript\ndescribe('Nutrition Data Accuracy', () => {\n  test('calories within 5% of USDA source');\n  test('macros within 5% of USDA source');\n  test('portion scaling maintains ratios');\n  test('cooking method adjustments reasonable');\n});\n```\n\n### Edge Case Tests\n\n#### Classification Edge Cases\n```python\ndef test_multiple_foods_in_image():\n    \"\"\"Should return primary classification or multi-food flag\"\"\"\n    \ndef test_partially_eaten_food():\n    \"\"\"Should still classify correctly\"\"\"\n    \ndef test_food_in_packaging():\n    \"\"\"Should suggest barcode scanning\"\"\"\n    \ndef test_non_food_image():\n    \"\"\"Should return low confidence / 'unknown'\"\"\"\n    \ndef test_blurry_image():\n    \"\"\"Should request better image or proceed with caution\"\"\"\n```\n\n#### Search Edge Cases\n```typescript\ndescribe('Search Edge Cases', () => {\n  test('handles Unicode characters (日本語, émoji)');\n  test('handles very long queries (>200 chars)');\n  test('handles SQL injection attempts');\n  test('handles empty/whitespace-only queries');\n  test('handles queries with only special characters');\n});\n```\n\n#### API Failure Edge Cases\n```typescript\ndescribe('API Resilience', () => {\n  test('handles USDA API timeout');\n  test('handles USDA API 500 errors');\n  test('handles rate limit exceeded (429)');\n  test('handles malformed USDA response');\n  test('circuit breaker activates after repeated failures');\n  test('fallback to cached data when API unavailable');\n});\n```\n\n### Feedback Loop Tests\n\n```typescript\ndescribe('Feedback Collection', () => {\n  test('feedback submitted successfully');\n  test('feedback deduplication works');\n  test('feedback aggregation triggers retraining signal');\n  test('feedback privacy (no PII stored)');\n});\n```\n\n### Load Tests\n\n```typescript\ndescribe('Load Testing', () => {\n  test('100 concurrent searches complete in <5s');\n  test('1000 searches/minute sustained without errors');\n  test('cache hit ratio >80% after warmup');\n  test('memory usage stable under load');\n});\n```\n\n### Acceptance Criteria\n\n#### Core Functionality\n- [ ] Search returns relevant results for common foods\n- [ ] Classification correctly categorizes >90% of test images\n- [ ] Nutrition data matches USDA source within 5%\n- [ ] Performance meets latency targets (search <500ms, classify <100ms)\n\n#### User Experience\n- [ ] User selects from top-5 suggestions >80% of time\n- [ ] Search autocomplete feels responsive (<300ms)\n- [ ] Classification confidence displayed helpfully\n- [ ] Graceful degradation when services unavailable\n\n#### System Reliability\n- [ ] Circuit breaker prevents cascade failures\n- [ ] Rate limiting prevents USDA API abuse\n- [ ] Caching reduces API calls by >80%\n- [ ] Offline mode provides useful functionality\n\n#### Data Quality\n- [ ] Nutrient mapping covers all essential nutrients\n- [ ] Serving size conversions accurate\n- [ ] Cooking method adjustments reasonable\n- [ ] Feedback loop improves suggestions over time",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement Barcode Scanner with Open Food Facts Integration",
        "description": "Add barcode scanning capability to the food logging flow using the device camera and integrate with Open Food Facts API for instant nutrition lookup. This addresses a critical competitive gap - MyFitnessPal's barcode scanner is one of their most-used features.",
        "details": "## Overview\nBarcode scanning is the #1 most requested feature for calorie tracking apps. Users expect instant food lookup by simply pointing their camera at a product barcode.\n\n## Technical Implementation\n\n### 1. Camera Barcode Scanner\n- Use `expo-camera` with barcode scanning enabled\n- Support EAN-13, EAN-8, UPC-A, UPC-E formats (standard food barcodes)\n- Implement scanning UI with viewfinder overlay and haptic feedback\n- Handle low-light conditions with torch toggle\n\n### 2. Open Food Facts API Integration\n- API endpoint: https://world.openfoodfacts.org/api/v0/product/{barcode}.json\n- Free, open-source database with 2M+ products\n- No API key required (rate limit: be respectful)\n- Implement caching layer to reduce API calls\n- Store successfully scanned products locally for offline access\n\n### 3. Data Mapping\nMap Open Food Facts response to Nutri's nutrition schema:\n- nutriments.energy-kcal_100g → calories (per 100g)\n- nutriments.proteins_100g → protein\n- nutriments.carbohydrates_100g → carbs\n- nutriments.fat_100g → fat\n- nutriments.fiber_100g → fiber\n- nutriments.sugars_100g → sugar\n- nutriments.sodium_100g → sodium\n- serving_size → portion reference\n\n### 4. UI/UX Flow\n1. User taps barcode icon in add-meal screen\n2. Camera opens with scanning viewfinder\n3. Barcode detected → API lookup\n4. Results shown: product name, image, nutrition per serving\n5. User can adjust serving size\n6. One-tap to add to meal log\n\n### 5. Fallback Handling\n- Product not found: Offer manual entry or AI food scanner\n- Network error: Check local cache first\n- Invalid barcode: Show helpful error message\n\n### 6. Files to Create/Modify\n- `app/scan-barcode.tsx` - New barcode scanner screen\n- `lib/api/openfoodfacts.ts` - API client\n- `lib/types/barcode.ts` - Type definitions\n- `app/add-meal.tsx` - Add barcode scanner button\n- `server/src/routes/foods.ts` - Cache endpoint (optional)\n\n## Success Metrics\n- Scanner accuracy: >95% successful reads\n- API hit rate: >80% products found\n- User adoption: 50%+ of food logs use barcode\n\n## Dependencies\n- expo-camera (already installed)\n- expo-haptics (for feedback)",
        "testStrategy": "1. Unit tests for Open Food Facts API client (mock responses)\n2. Unit tests for nutrition data mapping\n3. Integration tests for barcode detection\n4. E2E test: scan sample barcode → verify nutrition displayed\n5. Test offline caching behavior\n6. Test fallback flows (product not found, network error)",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-11T18:26:51.696Z"
      },
      {
        "id": 15,
        "title": "Build What-If Simulation Engine for Nutrition Impact Prediction",
        "description": "Create an interactive simulation feature that allows users to see predicted health impacts of potential nutrition changes before making them. This is a unique differentiator leveraging our ML correlation engine that no competitor offers.",
        "details": "## Overview\nWhat-If Simulation answers: \"If I change my diet in X way, how will it affect my health metrics?\" This transforms our ML predictions from passive insights to actionable planning tools.\n\n## Technical Implementation\n\n### 1. Simulation Engine (ML Service)\nCreate new service: `ml-service/app/services/simulation_engine.py`\n\nCore functionality:\n- Accept hypothetical nutrition changes (e.g., +20g protein daily)\n- Use trained LSTM models to predict health metric changes\n- Calculate confidence intervals for predictions\n- Return time-series projections (7-day, 14-day, 30-day)\n\n### 2. Simulation API Endpoints\n```python\nPOST /api/v1/simulate/nutrition-change\n{\n  \"user_id\": \"uuid\",\n  \"changes\": [\n    {\"nutrient\": \"protein\", \"delta\": 20, \"unit\": \"g\"},\n    {\"nutrient\": \"sugar\", \"delta\": -15, \"unit\": \"g\"}\n  ],\n  \"duration_days\": 14,\n  \"metrics_to_predict\": [\"rhr\", \"hrv_rmssd\", \"recovery_score\"]\n}\n\nResponse:\n{\n  \"predictions\": [\n    {\n      \"metric\": \"rhr\",\n      \"baseline\": 62,\n      \"projected\": 59,\n      \"confidence_interval\": [57, 61],\n      \"trajectory\": [62, 61, 61, 60, 60, 59, 59, ...]\n    }\n  ],\n  \"confidence_score\": 0.78,\n  \"based_on_correlations\": [...]\n}\n```\n\n### 3. Mobile UI Components\n- `app/simulate.tsx` - Main simulation screen\n- Slider controls for nutrition adjustments\n- Real-time prediction visualization\n- Before/after comparison charts\n- Save simulation as \"goal\" feature\n\n### 4. Visualization\n- Line chart showing projected metric trajectory\n- Confidence band visualization (shaded area)\n- Color coding: green (improvement), red (concern), gray (neutral)\n- Comparison overlay with current baseline\n\n### 5. Leveraging Existing ML\nBuild on `correlation_engine.py`:\n- Use discovered correlations to weight predictions\n- Apply time-lag findings (e.g., protein affects HRV after 48h)\n- Use per-user trained models for personalized predictions\n\n### 6. Safety Guardrails\n- Warn if simulated changes are extreme (>50% change)\n- Note that predictions are estimates, not medical advice\n- Cap prediction confidence for users with <30 days data\n\n## Success Metrics\n- Simulation accuracy: predictions within 15% of actual outcomes\n- User engagement: 30%+ users try simulation feature\n- Goal conversion: 20%+ of simulations saved as goals\n\n## Dependencies\n- Task 13: USDA database (for accurate nutrition data)\n- Existing correlation engine and LSTM models",
        "testStrategy": "1. Unit tests for simulation engine calculations\n2. Mock prediction model tests\n3. Integration tests for full simulation pipeline\n4. Validation: run simulations on historical data, compare to actual outcomes\n5. E2E test: create simulation → verify predictions displayed\n6. Test edge cases (insufficient data, extreme values)",
        "status": "pending",
        "dependencies": [
          "13"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Integrate Continuous Glucose Monitor (CGM) Data Sources",
        "description": "Add real-time glucose monitoring integration with major CGM platforms (Dexcom, Abbott Libre, Levels). This enables groundbreaking meal-specific glucose response tracking and positions Nutri as the premier nutrition-metabolic health app.",
        "details": "## Overview\nCGM integration is the next frontier in personalized nutrition. By correlating individual meal consumption with glucose response curves, we can provide unprecedented insights into how specific foods affect each user.\n\n## Technical Implementation\n\n### 1. CGM Platform Integrations\n\n#### Dexcom API\n- OAuth 2.0 authentication\n- Endpoints: /egvs (estimated glucose values)\n- 5-minute reading intervals\n- Developer portal: https://developer.dexcom.com/\n\n#### Abbott LibreView API\n- OAuth 2.0 authentication\n- Historical glucose data access\n- Developer access via partnership application\n\n#### Levels Health API (for Levels users)\n- REST API with API key\n- Enriched glucose data with metabolic scores\n- Partnership integration\n\n### 2. Data Models\n\nNew Prisma models:\n```prisma\nmodel GlucoseReading {\n  id          String   @id @default(uuid())\n  userId      String\n  value       Float    // mg/dL\n  source      GlucoseSource\n  recordedAt  DateTime\n  user        User     @relation(fields: [userId], references: [id])\n  \n  @@index([userId, recordedAt])\n}\n\nenum GlucoseSource {\n  DEXCOM\n  LIBRE\n  LEVELS\n  MANUAL\n}\n\nmodel MealGlucoseResponse {\n  id              String   @id @default(uuid())\n  mealId          String   @unique\n  meal            Meal     @relation(fields: [mealId], references: [id])\n  baselineGlucose Float\n  peakGlucose     Float\n  peakTime        Int      // minutes after meal\n  returnToBaseline Int     // minutes\n  areaUnderCurve  Float\n  glucoseScore    Float    // 0-100 metabolic response score\n}\n```\n\n### 3. Meal-Glucose Correlation\n\nNew ML service: `ml-service/app/services/glucose_analysis.py`\n\nFeatures:\n- Detect meal timing from glucose spikes\n- Calculate glucose response metrics per meal\n- Identify problematic foods for individual users\n- Learn personal glycemic index adjustments\n\n### 4. API Endpoints\n\n```\nPOST /api/v1/integrations/cgm/connect\nPOST /api/v1/integrations/cgm/sync\nGET /api/v1/glucose/readings?from=&to=\nGET /api/v1/glucose/meal-response/:mealId\nGET /api/v1/glucose/insights\n```\n\n### 5. Mobile UI\n\n- `app/settings/cgm-connect.tsx` - OAuth connection flow\n- `app/(tabs)/glucose.tsx` - Glucose dashboard tab (optional)\n- Glucose response card on meal detail view\n- Real-time glucose widget on home screen\n- Glucose trend visualization\n\n### 6. Privacy & Security\n\n- Encrypted storage of CGM credentials\n- User consent flow for data access\n- Data retention policies\n- HIPAA considerations for health data\n\n## Success Metrics\n- Integration success rate: >90% successful connections\n- Data sync reliability: >99% uptime\n- User value: 80%+ of CGM users find insights valuable\n\n## Dependencies\n- Backend OAuth infrastructure\n- Secure credential storage\n- Existing meal logging system",
        "testStrategy": "1. Unit tests for glucose data processing\n2. Mock OAuth flow tests\n3. Integration tests for each CGM provider API\n4. Test meal-glucose correlation calculations\n5. E2E test: connect CGM → sync data → view meal response\n6. Security audit for credential handling\n7. Test reconnection and token refresh flows",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Design Hierarchical Food Recognition Architecture",
        "description": "Document and implement the hierarchical food recognition architecture where the image classifier outputs food CATEGORIES (300-500 classes) that serve as search queries for USDA FoodData Central, NOT direct 500K-class classification which is infeasible.",
        "details": "## Architecture Decision Record\n\n### Problem Statement\nUSDA FoodData Central contains 500K+ foods. Should we train a classifier to recognize all of them?\n\n### Decision: NO - Use Hierarchical Architecture\n\n### Rationale\n\n**State of the Art Accuracy by Class Count:**\n- Food-101 (101 classes): 95% accuracy\n- Food-172 (172 classes): 94% accuracy  \n- Food-251 (251 classes): 81% accuracy\n- Food-256 (256 classes): 83% accuracy\n\nPattern: Every 2.5x increase = ~13% accuracy drop. At 500K classes, accuracy would be effectively random.\n\n**Visual Ambiguity Problem:**\nMany USDA items are visually identical:\n- \"Chicken breast, grilled, skin removed\" vs \"with skin\"\n- \"Brown rice, cooked\" vs \"white rice, cooked\"\n- Different brands of identical products\n\nNo classifier can distinguish these - only metadata and user confirmation can.\n\n### Target Architecture\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    FOOD RECOGNITION FLOW                     │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│  📷 Photo ──► Classifier (300-500 categories)               │\n│                    │                                        │\n│                    ▼                                        │\n│              \"chicken_breast\" (89% confidence)              │\n│                    │                                        │\n│                    ▼                                        │\n│  USDA Search: query=\"chicken breast\"                        │\n│                    │                                        │\n│                    ▼                                        │\n│  Results: [grilled/fried/roasted/raw variants...]           │\n│                    │                                        │\n│                    ▼                                        │\n│  User Confirms: \"Chicken breast, grilled, no skin\"          │\n│                    │                                        │\n│                    ▼                                        │\n│  AR Portion: 150g × nutrition/100g = Final Nutrition        │\n│                                                             │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Parallel Path: Barcode Scanner\n```\n📦 Barcode ──► USDA Branded Lookup ──► Exact Nutrition\n```\n\n### Implementation Tasks\n\n1. **Classifier Upgrade (Task 2)**\n   - Expand from 111 → 300-500 categories\n   - Architecture: Vision Transformer (ViT-B/16) or EfficientNet-B4\n   - Target: 85%+ top-5 accuracy\n   - Output: category string for USDA search\n\n2. **USDA Integration (Task 13)**\n   - Implement search API\n   - Category → search results mapping\n   - User confirmation UI\n\n3. **Barcode Scanner (Task 14)**\n   - Direct USDA branded lookup\n   - No classification needed\n\n### Category Taxonomy Design\n\nExpand current 111 classes following USDA structure:\n- Proteins: chicken_breast, chicken_thigh, beef_steak, ground_beef, salmon_fillet...\n- Grains: white_rice, brown_rice, pasta, bread_white, bread_wheat...\n- Vegetables: broccoli, spinach, carrot, potato_baked, potato_mashed...\n- Fruits: apple, banana, orange, strawberry, blueberry...\n- Dairy: milk, yogurt_plain, yogurt_greek, cheese_cheddar...\n- Mixed: pizza, burger, sandwich, salad, soup...\n\n### Success Metrics\n- Classifier top-5 accuracy: >85%\n- USDA search recall: >95% (correct item in top 10 results)\n- User confirmation rate: <2 taps to find correct item\n- End-to-end nutrition accuracy: within 10% of actual\n\n### References\n- SOTA Food Classification: ViT achieving 95% on Food-101\n- MyFitnessPal Meal Scan: Uses same hierarchical approach\n- USDA FoodData Central API: https://fdc.nal.usda.gov/api-guide/",
        "testStrategy": "1. Document review with team\n2. Validate category taxonomy covers 95%+ of common foods\n3. Prototype search flow with mock classifier output\n4. User testing of confirmation UI (target <2 taps)\n5. Accuracy benchmarking on held-out food images",
        "status": "pending",
        "dependencies": [
          "13"
        ],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-12-11T20:30:34.824Z",
      "taskCount": 16,
      "completedCount": 5,
      "tags": [
        "master"
      ],
      "created": "2025-12-12T19:59:09.756Z",
      "description": "Tasks for master context",
      "updated": "2025-12-12T19:59:09.756Z"
    }
  }
}
