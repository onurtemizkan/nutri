# =============================================================================
# Nutri Production Docker Compose
# Optimized for Hetzner Cloud/Dedicated Servers (AMD EPYC CPUs)
# =============================================================================
#
# Recommended Hetzner Instances:
#   - CPX31 (4 vCPU, 8GB RAM) - €9/mo - Good for MVP
#   - CCX23 (4 dedicated, 16GB RAM) - €25/mo - Better for growth
#
# Usage:
#   1. Copy .env.prod.example to .env.prod and fill in values
#   2. docker compose -f docker-compose.prod.yml --env-file .env.prod up -d --build
#   3. Access backend at http://localhost:3000
#
# First deployment (download models):
#   docker compose -f docker-compose.prod.yml --env-file .env.prod up -d
#   docker compose logs -f ml-service  # Wait for "ml_service_ready"
#
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # Backend API (Node.js/Express)
  # ---------------------------------------------------------------------------
  backend:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: nutri-backend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - JWT_SECRET=${JWT_SECRET}
      - JWT_EXPIRES_IN=${JWT_EXPIRES_IN:-7d}
      - PORT=3000
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - ML_SERVICE_URL=http://ml-service:8000
    ports:
      - "3000:3000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ml-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3000/health/live"]
      interval: 30s
      timeout: 10s
      start_period: 15s
      retries: 3
    networks:
      - nutri-network
    # Resource limits for Hetzner CPX31/CCX23
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # ML Service (Python/FastAPI) - Optimized for AMD EPYC
  # Internal only - not exposed to host, only accessible by backend
  # ---------------------------------------------------------------------------
  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: nutri-ml-service
    restart: unless-stopped
    environment:
      # Database & Cache
      - DATABASE_URL=${ML_DATABASE_URL:-postgresql+asyncpg://postgres:postgres@postgres:5432/nutri_db}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      # Application
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=INFO
      # -----------------------------------------------------------------------
      # ML Performance Settings
      # -----------------------------------------------------------------------
      - FAST_MODE=${FAST_MODE:-true}
      - COMPUTE_DEVICE=cpu
      - SKIP_MODEL_WARMUP=false
      # -----------------------------------------------------------------------
      # AMD EPYC Thread Optimization
      # Adjust based on instance: CPX31=4, CCX23=4, CPX21=3
      # -----------------------------------------------------------------------
      - OMP_NUM_THREADS=${OMP_NUM_THREADS:-4}
      - MKL_NUM_THREADS=${MKL_NUM_THREADS:-4}
      - OPENBLAS_NUM_THREADS=${OPENBLAS_NUM_THREADS:-4}
      - TORCH_NUM_THREADS=${TORCH_NUM_THREADS:-4}
      - NUMEXPR_NUM_THREADS=${NUMEXPR_NUM_THREADS:-4}
      # Disable CUDA search (CPU-only)
      - CUDA_VISIBLE_DEVICES=
      # ONNX Runtime
      - ORT_DISABLE_ALL_TELEMETRY=1
    volumes:
      # Persist HuggingFace models across restarts (saves ~2 min on startup)
      - ml_huggingface_cache:/home/mlservice/.cache/huggingface
    # Expose to internal network only (backend can reach it)
    expose:
      - "8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/live"]
      interval: 30s
      timeout: 10s
      # Model loading takes ~2 minutes on first start
      start_period: 180s
      retries: 5
    networks:
      - nutri-network
    # Resource limits for Hetzner CPX31/CCX23
    # ML service needs more resources than backend
    deploy:
      resources:
        limits:
          cpus: '3.0'
          memory: 6G
        reservations:
          cpus: '2.0'
          memory: 4G
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # PostgreSQL Database
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:16-alpine
    container_name: nutri-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-nutri_db}
      # Performance tuning for Hetzner instances
      POSTGRES_INITDB_ARGS: "--encoding=UTF8"
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "effective_cache_size=512MB"
      - "-c"
      - "work_mem=16MB"
      - "-c"
      - "maintenance_work_mem=64MB"
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
    # Not exposed to host in production - use DATABASE_URL from same network
    # Uncomment for debugging if needed:
    # ports:
    #   - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - nutri-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # Redis Cache
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: nutri-redis
    restart: unless-stopped
    # Production settings for Hetzner:
    # - 256MB max memory (sufficient for ML model caching)
    # - LRU eviction policy
    # - AOF persistence disabled for performance
    command: >
      redis-server
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly no
      --save ""
    volumes:
      - redis_prod_data:/data
    # Not exposed to host in production
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - nutri-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 300M
        reservations:
          cpus: '0.05'
          memory: 64M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

# -----------------------------------------------------------------------------
# Volumes - Named volumes for data persistence
# -----------------------------------------------------------------------------
volumes:
  postgres_prod_data:
    name: nutri_postgres_prod_data
  redis_prod_data:
    name: nutri_redis_prod_data
  ml_huggingface_cache:
    name: nutri_ml_huggingface_cache

# -----------------------------------------------------------------------------
# Networks
# -----------------------------------------------------------------------------
networks:
  nutri-network:
    name: nutri-prod-network
    driver: bridge
